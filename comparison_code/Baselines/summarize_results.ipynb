{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19953804",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86f5f64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_df(path):\n",
    "    df=pd.read_csv(path)\n",
    "#     df=df[df.Metric=='f1-score']\n",
    "    df['MID']=df['MID'].apply(lambda x: x.split('_')[1] if '_' in x else x)\n",
    "    df['MID_Num']=df['MID'].apply(lambda x: x[1:]).astype(int)\n",
    "    df=df[['MID','MID_Num','Classifier','Metric','Seizure']].sort_values('MID_Num').reset_index(drop=True).round(4)\n",
    "    df=df.pivot(index=['Classifier', 'Metric'], \n",
    "                      columns='MID_Num', \n",
    "                      values='Seizure')\n",
    "    \n",
    "    # Reset index to make Classifier and Metric regular columns\n",
    "    df_pivoted = df.reset_index()\n",
    "\n",
    "    # Optional: rename the columns index name to None for cleaner output\n",
    "    df_pivoted.columns.name = None\n",
    "\n",
    "    # Define the desired order of metrics\n",
    "    metric_order = ['precision', 'recall', 'f1-score', 'support']\n",
    "\n",
    "    # Reorder using categorical type\n",
    "    df_pivoted['Metric'] = pd.Categorical(df_pivoted['Metric'], \n",
    "                                           categories=metric_order, \n",
    "                                           ordered=True)\n",
    "\n",
    "    # Sort by Classifier and then by Metric\n",
    "    df_pivoted = df_pivoted.sort_values(['Classifier', 'Metric']).reset_index(drop=True)\n",
    "\n",
    "    return df_pivoted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e684637-3c58-431b-b212-f9a670059a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>0.6076</td>\n",
       "      <td>0.6402</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.6035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>0.2922</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.2420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3527</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.3389</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.7196</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.5967</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.7054</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8694</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.8060</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.6303</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.7949</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.8918</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.5377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.5466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.8391</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7661</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.4299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.8044</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>0.7698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8315</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.8479</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.8882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.8642</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.7451</td>\n",
       "      <td>0.8203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.4718</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>0.4445</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.4619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.9224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9493</td>\n",
       "      <td>0.8905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.9041</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.9009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "4   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "5   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "6   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "8         Decision Tree  precision  0.2650  0.2241  0.2410  0.2573  0.3417   \n",
       "9         Decision Tree     recall  0.5566  0.6616  0.4515  0.6045  0.5462   \n",
       "10        Decision Tree   f1-score  0.3590  0.3348  0.3142  0.3609  0.4204   \n",
       "12        Random Forest  precision  0.2701  0.2193  0.2299  0.2922  0.4574   \n",
       "13        Random Forest     recall  0.3527  0.5302  0.2532  0.4409  0.3454   \n",
       "14        Random Forest   f1-score  0.3059  0.3102  0.2410  0.3514  0.3936   \n",
       "16                  CNN  precision  0.0000  0.9133  0.0000  0.0000  0.9059   \n",
       "17                  CNN     recall  0.0000  0.6066  0.0000  0.0000  0.8912   \n",
       "18                  CNN   f1-score  0.0000  0.7290  0.0000  0.0000  0.8985   \n",
       "20         PyramidalCNN  precision  0.9984  0.8625  1.0000  1.0000  0.8426   \n",
       "21         PyramidalCNN     recall  0.1319  0.5967  0.0055  0.0730  0.9337   \n",
       "22         PyramidalCNN   f1-score  0.2330  0.7054  0.0109  0.1361  0.8858   \n",
       "24                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "25                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "26                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "28               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "29               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "30               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "32             ConvLSTM  precision  0.0000  0.9587  0.0000  0.0000  0.9735   \n",
       "33             ConvLSTM     recall  0.0000  0.6551  0.0000  0.0000  0.8694   \n",
       "34             ConvLSTM   f1-score  0.0000  0.7784  0.0000  0.0000  0.9185   \n",
       "36               EEGNet  precision  0.0341  0.8039  0.0596  0.0387  0.6839   \n",
       "37               EEGNet     recall  0.0353  0.3511  0.1085  0.0971  0.8585   \n",
       "38               EEGNet   f1-score  0.0347  0.4887  0.0769  0.0554  0.7613   \n",
       "40        InceptionTime  precision  0.9892  0.8940  1.0000  1.0000  0.9046   \n",
       "41        InceptionTime     recall  0.0749  0.6698  0.0097  0.1098  0.9130   \n",
       "42        InceptionTime   f1-score  0.1392  0.7658  0.0191  0.1979  0.9088   \n",
       "44             Xception  precision  0.0000  0.9262  0.0000  0.0000  0.9483   \n",
       "45             Xception     recall  0.0000  0.6532  0.0000  0.0000  0.9091   \n",
       "46             Xception   f1-score  0.0000  0.7661  0.0000  0.0000  0.9283   \n",
       "48                 UNet  precision  1.0000  0.0386  1.0000  1.0000  0.9313   \n",
       "49                 UNet     recall  0.0761  0.2531  0.0206  0.1688  0.8783   \n",
       "50                 UNet   f1-score  0.1414  0.0671  0.0404  0.2889  0.9040   \n",
       "52      SalientSleepNet  precision  0.8044  0.8478  0.8108  0.7440  0.7904   \n",
       "53      SalientSleepNet     recall  0.8315  0.6986  0.8968  0.9161  0.9640   \n",
       "54      SalientSleepNet   f1-score  0.8177  0.7660  0.8517  0.8211  0.8686   \n",
       "56             DETRtime  precision  0.0463  0.0463  0.0555  0.0433  0.0512   \n",
       "57             DETRtime     recall  0.4718  0.4616  0.4840  0.4445  0.4087   \n",
       "58             DETRtime   f1-score  0.0844  0.0841  0.0995  0.0789  0.0910   \n",
       "60     AugUNet1D (ours)  precision  0.9301  0.9672  0.9319  0.8871  0.9818   \n",
       "61     AugUNet1D (ours)     recall  0.8222  0.6147  0.9423  0.9672  0.8784   \n",
       "62     AugUNet1D (ours)   f1-score  0.8728  0.7517  0.9371  0.9254  0.9272   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "4   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "5   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "6   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "8   0.2567  0.3600  0.1758  0.1430  0.0926  0.2357  \n",
       "9   0.6076  0.6402  0.7475  0.6329  0.5866  0.6035  \n",
       "10  0.3609  0.4608  0.2846  0.2333  0.1599  0.3289  \n",
       "12  0.1984  0.3553  0.1950  0.1176  0.0849  0.2420  \n",
       "13  0.3080  0.3389  0.6881  0.4300  0.4302  0.4118  \n",
       "14  0.2413  0.3469  0.3038  0.1846  0.1418  0.2820  \n",
       "16  0.8532  0.8030  0.7937  0.8052  0.0000  0.5074  \n",
       "17  0.8821  0.9177  0.8611  0.7915  0.0000  0.4950  \n",
       "18  0.8674  0.8565  0.8260  0.7983  0.0000  0.4976  \n",
       "20  0.8451  0.7833  0.7196  0.7834  0.0000  0.7835  \n",
       "21  0.8961  0.9393  0.9706  0.8174  0.0000  0.5364  \n",
       "22  0.8698  0.8542  0.8264  0.8000  0.0000  0.5322  \n",
       "24  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "25  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "26  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "28  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "29  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "30  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "32  0.9883  0.9639  0.7972  0.9776  0.0000  0.5659  \n",
       "33  0.6648  0.8060  0.9283  0.6303  0.0000  0.4554  \n",
       "34  0.7949  0.8779  0.8578  0.7664  0.0000  0.4994  \n",
       "36  0.2942  0.6862  0.4720  0.5547  0.0124  0.3640  \n",
       "37  0.0240  0.2103  0.9653  0.1329  0.0524  0.2835  \n",
       "38  0.0443  0.3219  0.6340  0.2144  0.0200  0.2652  \n",
       "40  0.8918  0.8464  0.7168  0.8351  1.0000  0.9078  \n",
       "41  0.9087  0.9326  0.9428  0.8108  0.0052  0.5377  \n",
       "42  0.9002  0.8874  0.8144  0.8228  0.0103  0.5466  \n",
       "44  0.9413  0.9110  0.7928  0.9250  0.0000  0.5445  \n",
       "45  0.8391  0.9176  0.9565  0.7796  0.0000  0.5055  \n",
       "46  0.8872  0.9143  0.8670  0.8461  0.0000  0.5209  \n",
       "48  0.9577  0.9287  0.6520  0.9391  1.0000  0.8447  \n",
       "49  0.5398  0.6173  0.9320  0.4926  0.0059  0.3985  \n",
       "50  0.6904  0.7417  0.7672  0.6462  0.0117  0.4299  \n",
       "52  0.8427  0.7788  0.6565  0.7795  0.6430  0.7698  \n",
       "53  0.9193  0.9706  0.9519  0.8479  0.8858  0.8882  \n",
       "54  0.8793  0.8642  0.7771  0.8122  0.7451  0.8203  \n",
       "56  0.0565  0.0713  0.0326  0.0289  0.0144  0.0446  \n",
       "57  0.4834  0.4887  0.4432  0.4426  0.4902  0.4619  \n",
       "58  0.1011  0.1244  0.0608  0.0542  0.0280  0.0806  \n",
       "60  0.9532  0.9559  0.8493  0.9382  0.8288  0.9224  \n",
       "61  0.9504  0.9569  0.9510  0.8724  0.9493  0.8905  \n",
       "62  0.9518  0.9564  0.8973  0.9041  0.8850  0.9009  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline results\n",
    "base_path='./results_csvs/'\n",
    "\n",
    "base_files=[os.path.join(base_path,x) for x in os.listdir(base_path) if 'csv' in x]\n",
    "\n",
    "all_files=base_files+[\n",
    "    '../MLMethods/Logistic Regression_results.csv',\n",
    "    '../MLMethods/K-Nearest Neighbors_results.csv',\n",
    "    '../MLMethods/Decision Tree_results.csv',\n",
    "    '../MLMethods/Random Forest_results.csv',\n",
    "    '../DETRtime/DETRtime_results_v1.csv',\n",
    "    './augunet1D_results_v1.csv'\n",
    "]\n",
    "\n",
    "full_results=pd.DataFrame()\n",
    "for file in all_files:\n",
    "    df=process_df(file)\n",
    "    full_results=pd.concat([full_results, df])\n",
    "\n",
    "full_results.columns=full_results.columns[:2].tolist()+[f'M{x}' for x in full_results.columns[2:]]\n",
    "classifier_order=['Logistic Regression','K-Nearest Neighbors', 'Decision Tree', 'Random Forest',\n",
    "'CNN', 'PyramidalCNN',\n",
    "'LSTM','biLSTM','ConvLSTM',\n",
    "'EEGNet','InceptionTime','Xception','UNet','SalientSleepNet','DETRtime','AugUNet1D (ours)']\n",
    "# full_results=full_results.set_index(['Classifier', 'Metric'])\n",
    "# Create a categorical type with the custom order\n",
    "full_results['Classifier'] = pd.Categorical(full_results['Classifier'], \n",
    "                                   categories=classifier_order, \n",
    "                                   ordered=True)\n",
    "full_results = full_results.sort_values(['Classifier', 'Metric']).reset_index(drop=True)\n",
    "full_results = full_results[full_results.Metric!='support']\n",
    "full_results['avg']=full_results[[x for x in full_results.columns[2:]]].mean(axis=1)\n",
    "full_results = full_results.round(4)\n",
    "full_results.to_csv('full_results_v1.csv',index=False)\n",
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d369f9b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.2152</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3605</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5591</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.6038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.3249</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.3528</td>\n",
       "      <td>0.4634</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.2899</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.4749</td>\n",
       "      <td>0.4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.4015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.8227</td>\n",
       "      <td>0.7387</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.4343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.8170</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5988</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>0.8201</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.7291</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.7218</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.7669</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.8866</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.8577</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.8344</td>\n",
       "      <td>0.7627</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8959</td>\n",
       "      <td>0.9219</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.8494</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.4463</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.5111</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.6618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.7332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.7817</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9122</td>\n",
       "      <td>0.9515</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.8901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>0.9176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.8746</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.8581</td>\n",
       "      <td>0.9007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "4   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "5   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "6   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "8         Decision Tree  precision  0.2669  0.2152  0.2530  0.2524  0.3333   \n",
       "9         Decision Tree     recall  0.5591  0.6624  0.4515  0.6045  0.5542   \n",
       "10        Decision Tree   f1-score  0.3613  0.3249  0.3242  0.3561  0.4163   \n",
       "12        Random Forest  precision  0.2926  0.2309  0.2490  0.2899  0.4845   \n",
       "13        Random Forest     recall  0.3760  0.5641  0.2658  0.4455  0.3775   \n",
       "14        Random Forest   f1-score  0.3291  0.3276  0.2571  0.3513  0.4244   \n",
       "16                  CNN  precision  0.9713  0.8047  1.0000  1.0000  0.9661   \n",
       "17                  CNN     recall  0.0189  0.1266  0.0191  0.0241  0.6106   \n",
       "18                  CNN   f1-score  0.0371  0.2187  0.0375  0.0470  0.7482   \n",
       "20         PyramidalCNN  precision  0.0000  0.8947  0.0000  0.0000  0.8926   \n",
       "21         PyramidalCNN     recall  0.0000  0.5988  0.0000  0.0000  0.8724   \n",
       "22         PyramidalCNN   f1-score  0.0000  0.7174  0.0000  0.0000  0.8824   \n",
       "24                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "25                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "26                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "28               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "29               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "30               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "32             ConvLSTM  precision  0.0000  0.9226  0.0000  0.0000  0.9640   \n",
       "33             ConvLSTM     recall  0.0000  0.5478  0.0000  0.0000  0.8461   \n",
       "34             ConvLSTM   f1-score  0.0000  0.6875  0.0000  0.0000  0.9012   \n",
       "36               EEGNet  precision  0.0000  0.0194  0.0000  0.0000  0.0000   \n",
       "37               EEGNet     recall  0.0000  0.0001  0.0000  0.0000  0.0000   \n",
       "38               EEGNet   f1-score  0.0000  0.0002  0.0000  0.0000  0.0000   \n",
       "40        InceptionTime  precision  0.5556  0.8181  1.0000  1.0000  0.8463   \n",
       "41        InceptionTime     recall  0.0056  0.7218  0.0013  0.0072  0.9310   \n",
       "42        InceptionTime   f1-score  0.0110  0.7669  0.0026  0.0143  0.8866   \n",
       "44             Xception  precision  0.0000  0.9521  0.0000  0.0000  0.9030   \n",
       "45             Xception     recall  0.0000  0.5080  0.0000  0.0000  0.8959   \n",
       "46             Xception   f1-score  0.0000  0.6625  0.0000  0.0000  0.8994   \n",
       "48                 UNet  precision  0.9916  0.8684  0.9978  0.9852  0.9704   \n",
       "49                 UNet     recall  0.4463  0.3666  0.5111  0.6851  0.7982   \n",
       "50                 UNet   f1-score  0.6156  0.5156  0.6759  0.8082  0.8760   \n",
       "52      SalientSleepNet  precision  0.0000  0.1254  0.0000  0.0000  0.9638   \n",
       "53      SalientSleepNet     recall  0.0000  0.0139  0.0000  0.0000  0.1630   \n",
       "54      SalientSleepNet   f1-score  0.0000  0.0250  0.0000  0.0000  0.2788   \n",
       "56             DETRtime  precision  0.0652  0.0344  0.0011  0.0213  0.0753   \n",
       "57             DETRtime     recall  0.0184  0.0167  0.0003  0.0084  0.0274   \n",
       "58             DETRtime   f1-score  0.0287  0.0225  0.0005  0.0121  0.0402   \n",
       "60     AugUNet1D (ours)  precision  0.9122  0.9515  0.9135  0.8635  0.9438   \n",
       "61     AugUNet1D (ours)     recall  0.8435  0.7605  0.9428  0.9672  0.9234   \n",
       "62     AugUNet1D (ours)   f1-score  0.8765  0.8454  0.9279  0.9124  0.9335   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "4   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "5   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "6   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "8   0.2500  0.3605  0.1768  0.1370  0.0922  0.2337  \n",
       "9   0.5992  0.6485  0.7475  0.6184  0.5922  0.6038  \n",
       "10  0.3528  0.4634  0.2860  0.2244  0.1595  0.3269  \n",
       "12  0.2094  0.3624  0.2017  0.1399  0.0949  0.2555  \n",
       "13  0.3207  0.3473  0.7178  0.5217  0.4749  0.4411  \n",
       "14  0.2533  0.3547  0.3149  0.2206  0.1581  0.2991  \n",
       "16  0.8741  0.8650  0.7385  0.8322  1.0000  0.9052  \n",
       "17  0.8251  0.7886  0.9287  0.6642  0.0095  0.4015  \n",
       "18  0.8489  0.8251  0.8227  0.7387  0.0189  0.4343  \n",
       "20  0.8170  0.7826  0.7631  0.7779  0.0000  0.4928  \n",
       "21  0.9243  0.9462  0.9221  0.8192  0.0000  0.5083  \n",
       "22  0.8673  0.8567  0.8351  0.7980  0.0000  0.4957  \n",
       "24  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "25  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "26  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "28  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "29  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "30  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "32  0.9510  0.9378  0.8617  0.9352  0.0000  0.5572  \n",
       "33  0.6807  0.7287  0.8723  0.5975  0.0000  0.4273  \n",
       "34  0.7935  0.8201  0.8670  0.7291  0.0000  0.4798  \n",
       "36  0.0000  0.0000  0.7489  0.0000  0.0000  0.0768  \n",
       "37  0.0000  0.0000  0.7233  0.0000  0.0000  0.0723  \n",
       "38  0.0000  0.0000  0.7358  0.0000  0.0000  0.0736  \n",
       "40  0.8644  0.8160  0.7392  0.7983  1.0000  0.8438  \n",
       "41  0.8538  0.9039  0.9111  0.7807  0.0070  0.5123  \n",
       "42  0.8591  0.8577  0.8162  0.7894  0.0139  0.5018  \n",
       "44  0.8710  0.8344  0.7627  0.8091  0.0000  0.5132  \n",
       "45  0.9219  0.9400  0.9548  0.8494  0.0000  0.5070  \n",
       "46  0.8958  0.8841  0.8480  0.8288  0.0000  0.5019  \n",
       "48  0.9626  0.9407  0.4412  0.9461  0.9644  0.9068  \n",
       "49  0.7626  0.8116  0.9898  0.6470  0.5994  0.6618  \n",
       "50  0.8510  0.8714  0.6103  0.7685  0.7393  0.7332  \n",
       "52  0.0000  1.0000  0.6642  0.0000  0.0000  0.2753  \n",
       "53  0.0000  0.0031  0.9498  0.0000  0.0000  0.1130  \n",
       "54  0.0000  0.0061  0.7817  0.0000  0.0000  0.1092  \n",
       "56  0.0758  0.0326  0.0000  0.0527  0.0104  0.0369  \n",
       "57  0.0189  0.0102  0.0000  0.0315  0.0097  0.0142  \n",
       "58  0.0303  0.0155  0.0000  0.0394  0.0100  0.0199  \n",
       "60  0.9376  0.9200  0.8080  0.8745  0.7766  0.8901  \n",
       "61  0.9541  0.9685  0.9531  0.9047  0.9586  0.9176  \n",
       "62  0.9458  0.9436  0.8746  0.8893  0.8581  0.9007  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline results\n",
    "base_path='./results_csvs_v2/'\n",
    "\n",
    "base_files=[os.path.join(base_path,x) for x in os.listdir(base_path) if 'csv' in x]\n",
    "\n",
    "all_files=base_files+[\n",
    "    '../MLMethods/Logistic Regression_results_v2.csv',\n",
    "    '../MLMethods/K-Nearest Neighbors_results_v2.csv',\n",
    "    '../MLMethods/Decision Tree_results_v2.csv',\n",
    "    '../MLMethods/Random Forest_results_v2.csv',\n",
    "    '../DETRtime/DETRtime_results.csv',\n",
    "    './augunet1D_results_v2.csv'\n",
    "]\n",
    "\n",
    "full_results=pd.DataFrame()\n",
    "for file in all_files:\n",
    "    df=process_df(file)\n",
    "    full_results=pd.concat([full_results, df])\n",
    "\n",
    "full_results.columns=full_results.columns[:2].tolist()+[f'M{x}' for x in full_results.columns[2:]]\n",
    "classifier_order=['Logistic Regression','K-Nearest Neighbors', 'Decision Tree', 'Random Forest',\n",
    "'CNN', 'PyramidalCNN',\n",
    "'LSTM','biLSTM','ConvLSTM',\n",
    "'EEGNet','InceptionTime','Xception','UNet','SalientSleepNet','DETRtime','AugUNet1D (ours)']\n",
    "# full_results=full_results.set_index(['Classifier', 'Metric'])\n",
    "# Create a categorical type with the custom order\n",
    "full_results['Classifier'] = pd.Categorical(full_results['Classifier'], \n",
    "                                   categories=classifier_order, \n",
    "                                   ordered=True)\n",
    "full_results = full_results.sort_values(['Classifier', 'Metric']).reset_index(drop=True)\n",
    "full_results = full_results[full_results.Metric!='support']\n",
    "full_results['avg']=full_results[[x for x in full_results.columns[2:]]].mean(axis=1)\n",
    "full_results = full_results.round(4)\n",
    "full_results.to_csv('full_results_v2.csv',index=False)\n",
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f776a88-0032-433c-b3d1-c5593044ea1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.2314</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3702</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>0.4204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.7292</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8391</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.5786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.8885</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.8587</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.5628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.7230</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3156</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.4757</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.8631</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.8828</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.4917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.6912</td>\n",
       "      <td>0.8717</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9377</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.8917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.5373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3954</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.6066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.9037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.9402</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "4   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "5   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "6   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "8         Decision Tree  precision  0.2706  0.2184  0.2442  0.2573  0.3310   \n",
       "9         Decision Tree     recall  0.5624  0.6616  0.4430  0.6045  0.5622   \n",
       "10        Decision Tree   f1-score  0.3654  0.3283  0.3148  0.3609  0.4167   \n",
       "12        Random Forest  precision  0.2811  0.2247  0.2290  0.2801  0.4742   \n",
       "13        Random Forest     recall  0.3702  0.5471  0.2532  0.4227  0.3695   \n",
       "14        Random Forest   f1-score  0.3196  0.3186  0.2405  0.3370  0.4153   \n",
       "16                  CNN  precision  1.0000  0.9038  1.0000  1.0000  0.9002   \n",
       "17                  CNN     recall  0.0039  0.2828  0.0010  0.0047  0.8350   \n",
       "18                  CNN   f1-score  0.0077  0.4308  0.0019  0.0093  0.8664   \n",
       "20         PyramidalCNN  precision  0.9979  0.8683  1.0000  1.0000  0.8393   \n",
       "21         PyramidalCNN     recall  0.1635  0.6919  0.0039  0.1638  0.9438   \n",
       "22         PyramidalCNN   f1-score  0.2809  0.7701  0.0078  0.2815  0.8885   \n",
       "24                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "25                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "26                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "28               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "29               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "30               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "32             ConvLSTM  precision  0.0000  0.9560  0.0000  1.0000  0.9731   \n",
       "33             ConvLSTM     recall  0.0000  0.5207  0.0000  0.0002  0.8934   \n",
       "34             ConvLSTM   f1-score  0.0000  0.6742  0.0000  0.0005  0.9316   \n",
       "36               EEGNet  precision  0.0000  0.7868  0.0000  0.0000  0.9273   \n",
       "37               EEGNet     recall  0.0000  0.1974  0.0000  0.0000  0.8855   \n",
       "38               EEGNet   f1-score  0.0000  0.3156  0.0000  0.0000  0.9059   \n",
       "40        InceptionTime  precision  1.0000  0.9407  0.0000  1.0000  0.9175   \n",
       "41        InceptionTime     recall  0.0057  0.4757  0.0000  0.0032  0.8631   \n",
       "42        InceptionTime   f1-score  0.0113  0.6319  0.0000  0.0064  0.8894   \n",
       "44             Xception  precision  0.0485  0.9323  0.0584  0.0502  0.9119   \n",
       "45             Xception     recall  0.9309  0.6119  0.9334  0.9377  0.9254   \n",
       "46             Xception   f1-score  0.0922  0.7389  0.1100  0.0953  0.9186   \n",
       "48                 UNet  precision  0.9905  0.9650  0.9968  0.9949  0.9358   \n",
       "49                 UNet     recall  0.2470  0.4116  0.0765  0.3434  0.9081   \n",
       "50                 UNet   f1-score  0.3954  0.5770  0.1422  0.5106  0.9218   \n",
       "52      SalientSleepNet  precision  0.0000  0.8137  0.0000  0.0000  0.8132   \n",
       "53      SalientSleepNet     recall  0.0000  0.6146  0.0000  0.0000  0.9319   \n",
       "54      SalientSleepNet   f1-score  0.0000  0.7003  0.0000  0.0000  0.8685   \n",
       "56             DETRtime  precision  0.0561  0.0556  0.0779  0.0586  0.0642   \n",
       "57             DETRtime     recall  0.5345  0.4944  0.5862  0.5299  0.4926   \n",
       "58             DETRtime   f1-score  0.1016  0.0999  0.1374  0.1055  0.1136   \n",
       "60     AugUNet1D (ours)  precision  0.9037  0.9465  0.9127  0.8593  0.9792   \n",
       "61     AugUNet1D (ours)     recall  0.8444  0.5948  0.9402  0.9700  0.8826   \n",
       "62     AugUNet1D (ours)   f1-score  0.8730  0.7305  0.9262  0.9113  0.9284   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "4   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "5   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "6   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "8   0.2540  0.3581  0.1782  0.1421  0.0910  0.2345  \n",
       "9   0.6034  0.6444  0.7673  0.6232  0.5866  0.6059  \n",
       "10  0.3575  0.4604  0.2892  0.2314  0.1575  0.3282  \n",
       "12  0.2060  0.3565  0.1978  0.1182  0.0847  0.2452  \n",
       "13  0.3207  0.3431  0.7129  0.4396  0.4246  0.4204  \n",
       "14  0.2508  0.3497  0.3097  0.1863  0.1413  0.2869  \n",
       "16  0.9051  0.8528  0.7905  0.8489  0.0000  0.8201  \n",
       "17  0.7973  0.8681  0.8940  0.7292  0.0000  0.4416  \n",
       "18  0.8478  0.8604  0.8391  0.7845  0.0000  0.4648  \n",
       "20  0.7975  0.7674  0.6943  0.7546  1.0000  0.8719  \n",
       "21  0.9636  0.9748  0.9679  0.8910  0.0214  0.5786  \n",
       "22  0.8727  0.8587  0.8086  0.8172  0.0420  0.5628  \n",
       "24  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "25  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "26  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "28  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "29  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "30  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "32  0.9772  0.9506  0.8143  0.9592  0.0000  0.6630  \n",
       "33  0.7990  0.8823  0.9282  0.7230  0.0000  0.4747  \n",
       "34  0.8792  0.9152  0.8675  0.8245  0.0000  0.5093  \n",
       "36  0.0539  0.0676  0.6468  0.0307  0.0000  0.2513  \n",
       "37  0.9872  1.0000  0.8682  1.0000  0.0000  0.4938  \n",
       "38  0.1023  0.1266  0.7413  0.0595  0.0000  0.2251  \n",
       "40  0.8942  0.8569  0.6942  0.8397  1.0000  0.8143  \n",
       "41  0.8645  0.9102  0.9581  0.7727  0.0031  0.4856  \n",
       "42  0.8791  0.8828  0.8051  0.8048  0.0061  0.4917  \n",
       "44  0.8990  0.8698  0.6912  0.8717  0.0139  0.5347  \n",
       "45  0.9213  0.9524  0.9768  0.8184  0.9092  0.8917  \n",
       "46  0.9100  0.9092  0.8095  0.8442  0.0275  0.5455  \n",
       "48  0.9734  0.9463  0.6259  0.9480  0.9622  0.9339  \n",
       "49  0.7542  0.8281  0.9842  0.6970  0.1225  0.5373  \n",
       "50  0.8499  0.8833  0.7652  0.8034  0.2174  0.6066  \n",
       "52  0.8200  0.7690  0.6735  0.7704  0.0000  0.4660  \n",
       "53  0.9206  0.9471  0.9529  0.7981  0.0000  0.5165  \n",
       "54  0.8674  0.8488  0.7892  0.7840  0.0000  0.4858  \n",
       "56  0.0770  0.0885  0.0367  0.0355  0.0145  0.0565  \n",
       "57  0.5911  0.5440  0.4746  0.5215  0.4963  0.5265  \n",
       "58  0.1363  0.1522  0.0681  0.0665  0.0282  0.1009  \n",
       "60  0.9525  0.9518  0.8421  0.9194  0.7697  0.9037  \n",
       "61  0.9475  0.9546  0.9466  0.8867  0.9604  0.8928  \n",
       "62  0.9500  0.9532  0.8913  0.9027  0.8545  0.8921  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline results\n",
    "base_path='./results_csvs_v3/'\n",
    "\n",
    "base_files=[os.path.join(base_path,x) for x in os.listdir(base_path) if 'csv' in x]\n",
    "\n",
    "all_files=base_files+[\n",
    "    '../MLMethods/Logistic Regression_results_v3.csv',\n",
    "    '../MLMethods/K-Nearest Neighbors_results_v3.csv',\n",
    "    '../MLMethods/Decision Tree_results_v3.csv',\n",
    "    '../MLMethods/Random Forest_results_v3.csv',\n",
    "    '../DETRtime/DETRtime_results_v3.csv',\n",
    "    './augunet1D_results_v3.csv'\n",
    "]\n",
    "\n",
    "full_results=pd.DataFrame()\n",
    "for file in all_files:\n",
    "    df=process_df(file)\n",
    "    full_results=pd.concat([full_results, df])\n",
    "\n",
    "full_results.columns=full_results.columns[:2].tolist()+[f'M{x}' for x in full_results.columns[2:]]\n",
    "classifier_order=['Logistic Regression','K-Nearest Neighbors', 'Decision Tree', 'Random Forest',\n",
    "'CNN', 'PyramidalCNN',\n",
    "'LSTM','biLSTM','ConvLSTM',\n",
    "'EEGNet','InceptionTime','Xception','UNet','SalientSleepNet','DETRtime','AugUNet1D (ours)']\n",
    "# full_results=full_results.set_index(['Classifier', 'Metric'])\n",
    "# Create a categorical type with the custom order\n",
    "full_results['Classifier'] = pd.Categorical(full_results['Classifier'], \n",
    "                                   categories=classifier_order, \n",
    "                                   ordered=True)\n",
    "full_results = full_results.sort_values(['Classifier', 'Metric']).reset_index(drop=True)\n",
    "full_results = full_results[full_results.Metric!='support']\n",
    "full_results['avg']=full_results[[x for x in full_results.columns[2:]]].mean(axis=1)\n",
    "full_results = full_results.round(4)\n",
    "full_results.to_csv('full_results_v3.csv',index=False)\n",
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb0b6d4-656e-490c-bfe3-de9134596a7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.2314</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3702</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>0.4204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>0.7518</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>0.6743</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8354</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.8738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.5118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.5195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.4147</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.5841</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.4453</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.1459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.5511</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.7324</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>0.8466</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.7021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.6112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>0.5678</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>0.8842</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.3630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.3933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5792</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.8309</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.7735</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>0.8011</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.9037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.9402</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "4   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "5   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "6   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "8         Decision Tree  precision  0.2706  0.2184  0.2442  0.2573  0.3310   \n",
       "9         Decision Tree     recall  0.5624  0.6616  0.4430  0.6045  0.5622   \n",
       "10        Decision Tree   f1-score  0.3654  0.3283  0.3148  0.3609  0.4167   \n",
       "12        Random Forest  precision  0.2811  0.2247  0.2290  0.2801  0.4742   \n",
       "13        Random Forest     recall  0.3702  0.5471  0.2532  0.4227  0.3695   \n",
       "14        Random Forest   f1-score  0.3196  0.3186  0.2405  0.3370  0.4153   \n",
       "16                  CNN  precision  0.0000  0.8595  0.0000  0.0000  0.8680   \n",
       "17                  CNN     recall  0.0000  0.6818  0.0000  0.0000  0.8968   \n",
       "18                  CNN   f1-score  0.0000  0.7604  0.0000  0.0000  0.8822   \n",
       "20         PyramidalCNN  precision  0.9998  0.8874  0.9916  0.8995  0.8814   \n",
       "21         PyramidalCNN     recall  0.0197  0.5870  0.0133  0.0453  0.9310   \n",
       "22         PyramidalCNN   f1-score  0.0387  0.7066  0.0262  0.0862  0.9055   \n",
       "24                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "25                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "26                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "28               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "29               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "30               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "32             ConvLSTM  precision  0.9976  0.9372  1.0000  1.0000  0.9395   \n",
       "33             ConvLSTM     recall  0.0359  0.5772  0.0013  0.0506  0.9046   \n",
       "34             ConvLSTM   f1-score  0.0692  0.7144  0.0026  0.0963  0.9217   \n",
       "36               EEGNet  precision  0.0468  0.7365  0.0616  0.0475  0.0385   \n",
       "37               EEGNet     recall  0.0640  0.2551  0.0937  0.0897  0.0345   \n",
       "38               EEGNet   f1-score  0.0541  0.3789  0.0743  0.0621  0.0364   \n",
       "40        InceptionTime  precision  0.0000  0.9316  0.0000  0.0000  0.9775   \n",
       "41        InceptionTime     recall  0.0000  0.3443  0.0000  0.0000  0.7667   \n",
       "42        InceptionTime   f1-score  0.0000  0.5028  0.0000  0.0000  0.8594   \n",
       "44             Xception  precision  0.8449  0.8926  0.0000  0.8276  0.8703   \n",
       "45             Xception     recall  0.0026  0.7021  0.0000  0.0044  0.9555   \n",
       "46             Xception   f1-score  0.0052  0.7860  0.0000  0.0088  0.9109   \n",
       "48                 UNet  precision  0.5355  0.0560  0.3735  0.5700  0.8916   \n",
       "49                 UNet     recall  0.0347  0.2069  0.0294  0.0950  0.7912   \n",
       "50                 UNet   f1-score  0.0651  0.0881  0.0544  0.1628  0.8385   \n",
       "52      SalientSleepNet  precision  0.0000  0.5792  0.0000  0.0000  0.8636   \n",
       "53      SalientSleepNet     recall  0.0000  0.0470  0.0000  0.0000  0.8974   \n",
       "54      SalientSleepNet   f1-score  0.0000  0.0870  0.0000  0.0000  0.8802   \n",
       "56             DETRtime  precision  0.0561  0.0556  0.0779  0.0586  0.0642   \n",
       "57             DETRtime     recall  0.5345  0.4944  0.5862  0.5299  0.4926   \n",
       "58             DETRtime   f1-score  0.1016  0.0999  0.1374  0.1055  0.1136   \n",
       "60     AugUNet1D (ours)  precision  0.9037  0.9465  0.9127  0.8593  0.9792   \n",
       "61     AugUNet1D (ours)     recall  0.8444  0.5948  0.9402  0.9700  0.8826   \n",
       "62     AugUNet1D (ours)   f1-score  0.8730  0.7305  0.9262  0.9113  0.9284   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "4   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "5   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "6   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "8   0.2540  0.3581  0.1782  0.1421  0.0910  0.2345  \n",
       "9   0.6034  0.6444  0.7673  0.6232  0.5866  0.6059  \n",
       "10  0.3575  0.4604  0.2892  0.2314  0.1575  0.3282  \n",
       "12  0.2060  0.3565  0.1978  0.1182  0.0847  0.2452  \n",
       "13  0.3207  0.3431  0.7129  0.4396  0.4246  0.4204  \n",
       "14  0.2508  0.3497  0.3097  0.1863  0.1413  0.2869  \n",
       "16  0.9081  0.8641  0.7518  0.8596  0.0000  0.5111  \n",
       "17  0.7351  0.8041  0.8942  0.6743  0.0000  0.4686  \n",
       "18  0.8125  0.8330  0.8168  0.7558  0.0000  0.4861  \n",
       "20  0.8951  0.8354  0.7440  0.8454  0.7588  0.8738  \n",
       "21  0.8714  0.9276  0.9091  0.7987  0.0151  0.5118  \n",
       "22  0.8831  0.8791  0.8183  0.8214  0.0295  0.5195  \n",
       "24  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "25  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "26  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "28  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "29  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "30  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "32  0.9980  0.9872  0.7918  0.9882  0.0000  0.8640  \n",
       "33  0.0996  0.4147  0.9660  0.2874  0.0000  0.3337  \n",
       "34  0.1812  0.5841  0.8703  0.4453  0.0000  0.3885  \n",
       "36  0.0592  0.0442  0.3900  0.0207  0.0141  0.1459  \n",
       "37  0.1109  0.0565  0.9388  0.0654  0.0685  0.1777  \n",
       "38  0.0772  0.0496  0.5511  0.0314  0.0233  0.1338  \n",
       "40  0.9023  0.8877  0.7324  0.8704  0.0000  0.5302  \n",
       "41  0.8408  0.8466  0.9023  0.7447  0.0000  0.4445  \n",
       "42  0.8704  0.8667  0.8085  0.8027  0.0000  0.4711  \n",
       "44  0.8859  0.8692  0.7420  0.8759  0.0000  0.6808  \n",
       "45  0.9375  0.9659  0.9135  0.8406  0.0000  0.5322  \n",
       "46  0.9110  0.9150  0.8189  0.8579  0.0000  0.5214  \n",
       "48  0.9544  0.9335  0.5433  0.9506  0.3037  0.6112  \n",
       "49  0.5678  0.5572  0.8842  0.4436  0.0195  0.3630  \n",
       "50  0.7120  0.6979  0.6730  0.6050  0.0366  0.3933  \n",
       "52  0.8877  0.8285  0.7122  0.8309  0.0000  0.4702  \n",
       "53  0.8747  0.9241  0.9185  0.7735  0.0000  0.4435  \n",
       "54  0.8812  0.8737  0.8023  0.8011  0.0000  0.4326  \n",
       "56  0.0770  0.0885  0.0367  0.0355  0.0145  0.0565  \n",
       "57  0.5911  0.5440  0.4746  0.5215  0.4963  0.5265  \n",
       "58  0.1363  0.1522  0.0681  0.0665  0.0282  0.1009  \n",
       "60  0.9525  0.9518  0.8421  0.9194  0.7697  0.9037  \n",
       "61  0.9475  0.9546  0.9466  0.8867  0.9604  0.8928  \n",
       "62  0.9500  0.9532  0.8913  0.9027  0.8545  0.8921  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#baseline results\n",
    "base_path='./results_csvs_v4/'\n",
    "\n",
    "base_files=[os.path.join(base_path,x) for x in os.listdir(base_path) if 'csv' in x]\n",
    "\n",
    "all_files=base_files+[\n",
    "    '../MLMethods/Logistic Regression_results_v3.csv',\n",
    "    '../MLMethods/K-Nearest Neighbors_results_v3.csv',\n",
    "    '../MLMethods/Decision Tree_results_v3.csv',\n",
    "    '../MLMethods/Random Forest_results_v3.csv',\n",
    "    '../DETRtime/DETRtime_results_v3.csv',\n",
    "    './augunet1D_results_v3.csv'\n",
    "]\n",
    "\n",
    "full_results=pd.DataFrame()\n",
    "for file in all_files:\n",
    "    df=process_df(file)\n",
    "    full_results=pd.concat([full_results, df])\n",
    "\n",
    "full_results.columns=full_results.columns[:2].tolist()+[f'M{x}' for x in full_results.columns[2:]]\n",
    "classifier_order=['Logistic Regression','K-Nearest Neighbors', 'Decision Tree', 'Random Forest',\n",
    "'CNN', 'PyramidalCNN',\n",
    "'LSTM','biLSTM','ConvLSTM',\n",
    "'EEGNet','InceptionTime','Xception','UNet','SalientSleepNet','DETRtime','AugUNet1D (ours)']\n",
    "# full_results=full_results.set_index(['Classifier', 'Metric'])\n",
    "# Create a categorical type with the custom order\n",
    "full_results['Classifier'] = pd.Categorical(full_results['Classifier'], \n",
    "                                   categories=classifier_order, \n",
    "                                   ordered=True)\n",
    "full_results = full_results.sort_values(['Classifier', 'Metric']).reset_index(drop=True)\n",
    "full_results = full_results[full_results.Metric!='support']\n",
    "full_results['avg']=full_results[[x for x in full_results.columns[2:]]].mean(axis=1)\n",
    "full_results = full_results.round(4)\n",
    "full_results.to_csv('full_results_v4.csv',index=False)\n",
    "full_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e7c980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=pd.read_csv('./full_results_v1.csv')\n",
    "v2=pd.read_csv('./full_results_v2.csv')\n",
    "v3=pd.read_csv('./full_results_v3.csv')\n",
    "v4=pd.read_csv('./full_results_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65e056f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.2241</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3417</td>\n",
       "      <td>0.2567</td>\n",
       "      <td>0.3600</td>\n",
       "      <td>0.1758</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0926</td>\n",
       "      <td>0.2357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5566</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5462</td>\n",
       "      <td>0.6076</td>\n",
       "      <td>0.6402</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.6329</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.6035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3590</td>\n",
       "      <td>0.3348</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4204</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4608</td>\n",
       "      <td>0.2846</td>\n",
       "      <td>0.2333</td>\n",
       "      <td>0.1599</td>\n",
       "      <td>0.3289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2701</td>\n",
       "      <td>0.2193</td>\n",
       "      <td>0.2299</td>\n",
       "      <td>0.2922</td>\n",
       "      <td>0.4574</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.3553</td>\n",
       "      <td>0.1950</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.0849</td>\n",
       "      <td>0.2420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3527</td>\n",
       "      <td>0.5302</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.4409</td>\n",
       "      <td>0.3454</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>0.3389</td>\n",
       "      <td>0.6881</td>\n",
       "      <td>0.4300</td>\n",
       "      <td>0.4302</td>\n",
       "      <td>0.4118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3059</td>\n",
       "      <td>0.3102</td>\n",
       "      <td>0.2410</td>\n",
       "      <td>0.3514</td>\n",
       "      <td>0.3936</td>\n",
       "      <td>0.2413</td>\n",
       "      <td>0.3469</td>\n",
       "      <td>0.3038</td>\n",
       "      <td>0.1846</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9133</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.8532</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>0.7937</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8912</td>\n",
       "      <td>0.8821</td>\n",
       "      <td>0.9177</td>\n",
       "      <td>0.8611</td>\n",
       "      <td>0.7915</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7290</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8985</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.8565</td>\n",
       "      <td>0.8260</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9984</td>\n",
       "      <td>0.8625</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8426</td>\n",
       "      <td>0.8451</td>\n",
       "      <td>0.7833</td>\n",
       "      <td>0.7196</td>\n",
       "      <td>0.7834</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.1319</td>\n",
       "      <td>0.5967</td>\n",
       "      <td>0.0055</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.9337</td>\n",
       "      <td>0.8961</td>\n",
       "      <td>0.9393</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.8174</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2330</td>\n",
       "      <td>0.7054</td>\n",
       "      <td>0.0109</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.8542</td>\n",
       "      <td>0.8264</td>\n",
       "      <td>0.8000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9587</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9735</td>\n",
       "      <td>0.9883</td>\n",
       "      <td>0.9639</td>\n",
       "      <td>0.7972</td>\n",
       "      <td>0.9776</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6551</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8694</td>\n",
       "      <td>0.6648</td>\n",
       "      <td>0.8060</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.6303</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7784</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.7949</td>\n",
       "      <td>0.8779</td>\n",
       "      <td>0.8578</td>\n",
       "      <td>0.7664</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0341</td>\n",
       "      <td>0.8039</td>\n",
       "      <td>0.0596</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.6839</td>\n",
       "      <td>0.2942</td>\n",
       "      <td>0.6862</td>\n",
       "      <td>0.4720</td>\n",
       "      <td>0.5547</td>\n",
       "      <td>0.0124</td>\n",
       "      <td>0.3640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0353</td>\n",
       "      <td>0.3511</td>\n",
       "      <td>0.1085</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.8585</td>\n",
       "      <td>0.0240</td>\n",
       "      <td>0.2103</td>\n",
       "      <td>0.9653</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0524</td>\n",
       "      <td>0.2835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.0554</td>\n",
       "      <td>0.7613</td>\n",
       "      <td>0.0443</td>\n",
       "      <td>0.3219</td>\n",
       "      <td>0.6340</td>\n",
       "      <td>0.2144</td>\n",
       "      <td>0.0200</td>\n",
       "      <td>0.2652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9892</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.8918</td>\n",
       "      <td>0.8464</td>\n",
       "      <td>0.7168</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0749</td>\n",
       "      <td>0.6698</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.9130</td>\n",
       "      <td>0.9087</td>\n",
       "      <td>0.9326</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.5377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>0.7658</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.1979</td>\n",
       "      <td>0.9088</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.8144</td>\n",
       "      <td>0.8228</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.5466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9483</td>\n",
       "      <td>0.9413</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.7928</td>\n",
       "      <td>0.9250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6532</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.8391</td>\n",
       "      <td>0.9176</td>\n",
       "      <td>0.9565</td>\n",
       "      <td>0.7796</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7661</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9283</td>\n",
       "      <td>0.8872</td>\n",
       "      <td>0.9143</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9313</td>\n",
       "      <td>0.9577</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.6520</td>\n",
       "      <td>0.9391</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.2531</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1688</td>\n",
       "      <td>0.8783</td>\n",
       "      <td>0.5398</td>\n",
       "      <td>0.6173</td>\n",
       "      <td>0.9320</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.3985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1414</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.0404</td>\n",
       "      <td>0.2889</td>\n",
       "      <td>0.9040</td>\n",
       "      <td>0.6904</td>\n",
       "      <td>0.7417</td>\n",
       "      <td>0.7672</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.4299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.8044</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.8108</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.7904</td>\n",
       "      <td>0.8427</td>\n",
       "      <td>0.7788</td>\n",
       "      <td>0.6565</td>\n",
       "      <td>0.7795</td>\n",
       "      <td>0.6430</td>\n",
       "      <td>0.7698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8315</td>\n",
       "      <td>0.6986</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.9161</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9193</td>\n",
       "      <td>0.9706</td>\n",
       "      <td>0.9519</td>\n",
       "      <td>0.8479</td>\n",
       "      <td>0.8858</td>\n",
       "      <td>0.8882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8177</td>\n",
       "      <td>0.7660</td>\n",
       "      <td>0.8517</td>\n",
       "      <td>0.8211</td>\n",
       "      <td>0.8686</td>\n",
       "      <td>0.8793</td>\n",
       "      <td>0.8642</td>\n",
       "      <td>0.7771</td>\n",
       "      <td>0.8122</td>\n",
       "      <td>0.7451</td>\n",
       "      <td>0.8203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.0555</td>\n",
       "      <td>0.0433</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.0713</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0144</td>\n",
       "      <td>0.0446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.4718</td>\n",
       "      <td>0.4616</td>\n",
       "      <td>0.4840</td>\n",
       "      <td>0.4445</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.4834</td>\n",
       "      <td>0.4887</td>\n",
       "      <td>0.4432</td>\n",
       "      <td>0.4426</td>\n",
       "      <td>0.4902</td>\n",
       "      <td>0.4619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0844</td>\n",
       "      <td>0.0841</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1011</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>0.0608</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.0280</td>\n",
       "      <td>0.0806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9301</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.8871</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.9559</td>\n",
       "      <td>0.8493</td>\n",
       "      <td>0.9382</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.9224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8222</td>\n",
       "      <td>0.6147</td>\n",
       "      <td>0.9423</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.8784</td>\n",
       "      <td>0.9504</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9493</td>\n",
       "      <td>0.8905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8728</td>\n",
       "      <td>0.7517</td>\n",
       "      <td>0.9371</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9272</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.9564</td>\n",
       "      <td>0.8973</td>\n",
       "      <td>0.9041</td>\n",
       "      <td>0.8850</td>\n",
       "      <td>0.9009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "3   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "4   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "5   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "6         Decision Tree  precision  0.2650  0.2241  0.2410  0.2573  0.3417   \n",
       "7         Decision Tree     recall  0.5566  0.6616  0.4515  0.6045  0.5462   \n",
       "8         Decision Tree   f1-score  0.3590  0.3348  0.3142  0.3609  0.4204   \n",
       "9         Random Forest  precision  0.2701  0.2193  0.2299  0.2922  0.4574   \n",
       "10        Random Forest     recall  0.3527  0.5302  0.2532  0.4409  0.3454   \n",
       "11        Random Forest   f1-score  0.3059  0.3102  0.2410  0.3514  0.3936   \n",
       "12                  CNN  precision  0.0000  0.9133  0.0000  0.0000  0.9059   \n",
       "13                  CNN     recall  0.0000  0.6066  0.0000  0.0000  0.8912   \n",
       "14                  CNN   f1-score  0.0000  0.7290  0.0000  0.0000  0.8985   \n",
       "15         PyramidalCNN  precision  0.9984  0.8625  1.0000  1.0000  0.8426   \n",
       "16         PyramidalCNN     recall  0.1319  0.5967  0.0055  0.0730  0.9337   \n",
       "17         PyramidalCNN   f1-score  0.2330  0.7054  0.0109  0.1361  0.8858   \n",
       "18                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "19                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "20                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "21               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "22               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "23               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "24             ConvLSTM  precision  0.0000  0.9587  0.0000  0.0000  0.9735   \n",
       "25             ConvLSTM     recall  0.0000  0.6551  0.0000  0.0000  0.8694   \n",
       "26             ConvLSTM   f1-score  0.0000  0.7784  0.0000  0.0000  0.9185   \n",
       "27               EEGNet  precision  0.0341  0.8039  0.0596  0.0387  0.6839   \n",
       "28               EEGNet     recall  0.0353  0.3511  0.1085  0.0971  0.8585   \n",
       "29               EEGNet   f1-score  0.0347  0.4887  0.0769  0.0554  0.7613   \n",
       "30        InceptionTime  precision  0.9892  0.8940  1.0000  1.0000  0.9046   \n",
       "31        InceptionTime     recall  0.0749  0.6698  0.0097  0.1098  0.9130   \n",
       "32        InceptionTime   f1-score  0.1392  0.7658  0.0191  0.1979  0.9088   \n",
       "33             Xception  precision  0.0000  0.9262  0.0000  0.0000  0.9483   \n",
       "34             Xception     recall  0.0000  0.6532  0.0000  0.0000  0.9091   \n",
       "35             Xception   f1-score  0.0000  0.7661  0.0000  0.0000  0.9283   \n",
       "36                 UNet  precision  1.0000  0.0386  1.0000  1.0000  0.9313   \n",
       "37                 UNet     recall  0.0761  0.2531  0.0206  0.1688  0.8783   \n",
       "38                 UNet   f1-score  0.1414  0.0671  0.0404  0.2889  0.9040   \n",
       "39      SalientSleepNet  precision  0.8044  0.8478  0.8108  0.7440  0.7904   \n",
       "40      SalientSleepNet     recall  0.8315  0.6986  0.8968  0.9161  0.9640   \n",
       "41      SalientSleepNet   f1-score  0.8177  0.7660  0.8517  0.8211  0.8686   \n",
       "42             DETRtime  precision  0.0463  0.0463  0.0555  0.0433  0.0512   \n",
       "43             DETRtime     recall  0.4718  0.4616  0.4840  0.4445  0.4087   \n",
       "44             DETRtime   f1-score  0.0844  0.0841  0.0995  0.0789  0.0910   \n",
       "45     AugUNet1D (ours)  precision  0.9301  0.9672  0.9319  0.8871  0.9818   \n",
       "46     AugUNet1D (ours)     recall  0.8222  0.6147  0.9423  0.9672  0.8784   \n",
       "47     AugUNet1D (ours)   f1-score  0.8728  0.7517  0.9371  0.9254  0.9272   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "3   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "4   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "5   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "6   0.2567  0.3600  0.1758  0.1430  0.0926  0.2357  \n",
       "7   0.6076  0.6402  0.7475  0.6329  0.5866  0.6035  \n",
       "8   0.3609  0.4608  0.2846  0.2333  0.1599  0.3289  \n",
       "9   0.1984  0.3553  0.1950  0.1176  0.0849  0.2420  \n",
       "10  0.3080  0.3389  0.6881  0.4300  0.4302  0.4118  \n",
       "11  0.2413  0.3469  0.3038  0.1846  0.1418  0.2820  \n",
       "12  0.8532  0.8030  0.7937  0.8052  0.0000  0.5074  \n",
       "13  0.8821  0.9177  0.8611  0.7915  0.0000  0.4950  \n",
       "14  0.8674  0.8565  0.8260  0.7983  0.0000  0.4976  \n",
       "15  0.8451  0.7833  0.7196  0.7834  0.0000  0.7835  \n",
       "16  0.8961  0.9393  0.9706  0.8174  0.0000  0.5364  \n",
       "17  0.8698  0.8542  0.8264  0.8000  0.0000  0.5322  \n",
       "18  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "19  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "20  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "21  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "22  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "23  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "24  0.9883  0.9639  0.7972  0.9776  0.0000  0.5659  \n",
       "25  0.6648  0.8060  0.9283  0.6303  0.0000  0.4554  \n",
       "26  0.7949  0.8779  0.8578  0.7664  0.0000  0.4994  \n",
       "27  0.2942  0.6862  0.4720  0.5547  0.0124  0.3640  \n",
       "28  0.0240  0.2103  0.9653  0.1329  0.0524  0.2835  \n",
       "29  0.0443  0.3219  0.6340  0.2144  0.0200  0.2652  \n",
       "30  0.8918  0.8464  0.7168  0.8351  1.0000  0.9078  \n",
       "31  0.9087  0.9326  0.9428  0.8108  0.0052  0.5377  \n",
       "32  0.9002  0.8874  0.8144  0.8228  0.0103  0.5466  \n",
       "33  0.9413  0.9110  0.7928  0.9250  0.0000  0.5445  \n",
       "34  0.8391  0.9176  0.9565  0.7796  0.0000  0.5055  \n",
       "35  0.8872  0.9143  0.8670  0.8461  0.0000  0.5209  \n",
       "36  0.9577  0.9287  0.6520  0.9391  1.0000  0.8447  \n",
       "37  0.5398  0.6173  0.9320  0.4926  0.0059  0.3985  \n",
       "38  0.6904  0.7417  0.7672  0.6462  0.0117  0.4299  \n",
       "39  0.8427  0.7788  0.6565  0.7795  0.6430  0.7698  \n",
       "40  0.9193  0.9706  0.9519  0.8479  0.8858  0.8882  \n",
       "41  0.8793  0.8642  0.7771  0.8122  0.7451  0.8203  \n",
       "42  0.0565  0.0713  0.0326  0.0289  0.0144  0.0446  \n",
       "43  0.4834  0.4887  0.4432  0.4426  0.4902  0.4619  \n",
       "44  0.1011  0.1244  0.0608  0.0542  0.0280  0.0806  \n",
       "45  0.9532  0.9559  0.8493  0.9382  0.8288  0.9224  \n",
       "46  0.9504  0.9569  0.9510  0.8724  0.9493  0.8905  \n",
       "47  0.9518  0.9564  0.8973  0.9041  0.8850  0.9009  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a4a41398",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2669</td>\n",
       "      <td>0.2152</td>\n",
       "      <td>0.2530</td>\n",
       "      <td>0.2524</td>\n",
       "      <td>0.3333</td>\n",
       "      <td>0.2500</td>\n",
       "      <td>0.3605</td>\n",
       "      <td>0.1768</td>\n",
       "      <td>0.1370</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.2337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5591</td>\n",
       "      <td>0.6624</td>\n",
       "      <td>0.4515</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5542</td>\n",
       "      <td>0.5992</td>\n",
       "      <td>0.6485</td>\n",
       "      <td>0.7475</td>\n",
       "      <td>0.6184</td>\n",
       "      <td>0.5922</td>\n",
       "      <td>0.6038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.3249</td>\n",
       "      <td>0.3242</td>\n",
       "      <td>0.3561</td>\n",
       "      <td>0.4163</td>\n",
       "      <td>0.3528</td>\n",
       "      <td>0.4634</td>\n",
       "      <td>0.2860</td>\n",
       "      <td>0.2244</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2926</td>\n",
       "      <td>0.2309</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>0.2899</td>\n",
       "      <td>0.4845</td>\n",
       "      <td>0.2094</td>\n",
       "      <td>0.3624</td>\n",
       "      <td>0.2017</td>\n",
       "      <td>0.1399</td>\n",
       "      <td>0.0949</td>\n",
       "      <td>0.2555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3760</td>\n",
       "      <td>0.5641</td>\n",
       "      <td>0.2658</td>\n",
       "      <td>0.4455</td>\n",
       "      <td>0.3775</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3473</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>0.5217</td>\n",
       "      <td>0.4749</td>\n",
       "      <td>0.4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3291</td>\n",
       "      <td>0.3276</td>\n",
       "      <td>0.2571</td>\n",
       "      <td>0.3513</td>\n",
       "      <td>0.4244</td>\n",
       "      <td>0.2533</td>\n",
       "      <td>0.3547</td>\n",
       "      <td>0.3149</td>\n",
       "      <td>0.2206</td>\n",
       "      <td>0.1581</td>\n",
       "      <td>0.2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9713</td>\n",
       "      <td>0.8047</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9661</td>\n",
       "      <td>0.8741</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.7385</td>\n",
       "      <td>0.8322</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.0191</td>\n",
       "      <td>0.0241</td>\n",
       "      <td>0.6106</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>0.9287</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.0095</td>\n",
       "      <td>0.4015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0371</td>\n",
       "      <td>0.2187</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.7482</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.8251</td>\n",
       "      <td>0.8227</td>\n",
       "      <td>0.7387</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.4343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.8170</td>\n",
       "      <td>0.7826</td>\n",
       "      <td>0.7631</td>\n",
       "      <td>0.7779</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5988</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8724</td>\n",
       "      <td>0.9243</td>\n",
       "      <td>0.9462</td>\n",
       "      <td>0.9221</td>\n",
       "      <td>0.8192</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7174</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8824</td>\n",
       "      <td>0.8673</td>\n",
       "      <td>0.8567</td>\n",
       "      <td>0.8351</td>\n",
       "      <td>0.7980</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9226</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9640</td>\n",
       "      <td>0.9510</td>\n",
       "      <td>0.9378</td>\n",
       "      <td>0.8617</td>\n",
       "      <td>0.9352</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5478</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8461</td>\n",
       "      <td>0.6807</td>\n",
       "      <td>0.7287</td>\n",
       "      <td>0.8723</td>\n",
       "      <td>0.5975</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6875</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9012</td>\n",
       "      <td>0.7935</td>\n",
       "      <td>0.8201</td>\n",
       "      <td>0.8670</td>\n",
       "      <td>0.7291</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0768</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7233</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7358</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.5556</td>\n",
       "      <td>0.8181</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8463</td>\n",
       "      <td>0.8644</td>\n",
       "      <td>0.8160</td>\n",
       "      <td>0.7392</td>\n",
       "      <td>0.7983</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.7218</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0072</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.8538</td>\n",
       "      <td>0.9039</td>\n",
       "      <td>0.9111</td>\n",
       "      <td>0.7807</td>\n",
       "      <td>0.0070</td>\n",
       "      <td>0.5123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.7669</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0143</td>\n",
       "      <td>0.8866</td>\n",
       "      <td>0.8591</td>\n",
       "      <td>0.8577</td>\n",
       "      <td>0.8162</td>\n",
       "      <td>0.7894</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9521</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9030</td>\n",
       "      <td>0.8710</td>\n",
       "      <td>0.8344</td>\n",
       "      <td>0.7627</td>\n",
       "      <td>0.8091</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8959</td>\n",
       "      <td>0.9219</td>\n",
       "      <td>0.9400</td>\n",
       "      <td>0.9548</td>\n",
       "      <td>0.8494</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6625</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8994</td>\n",
       "      <td>0.8958</td>\n",
       "      <td>0.8841</td>\n",
       "      <td>0.8480</td>\n",
       "      <td>0.8288</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.8684</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>0.9852</td>\n",
       "      <td>0.9704</td>\n",
       "      <td>0.9626</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.4412</td>\n",
       "      <td>0.9461</td>\n",
       "      <td>0.9644</td>\n",
       "      <td>0.9068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.4463</td>\n",
       "      <td>0.3666</td>\n",
       "      <td>0.5111</td>\n",
       "      <td>0.6851</td>\n",
       "      <td>0.7982</td>\n",
       "      <td>0.7626</td>\n",
       "      <td>0.8116</td>\n",
       "      <td>0.9898</td>\n",
       "      <td>0.6470</td>\n",
       "      <td>0.5994</td>\n",
       "      <td>0.6618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.6156</td>\n",
       "      <td>0.5156</td>\n",
       "      <td>0.6759</td>\n",
       "      <td>0.8082</td>\n",
       "      <td>0.8760</td>\n",
       "      <td>0.8510</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.6103</td>\n",
       "      <td>0.7685</td>\n",
       "      <td>0.7393</td>\n",
       "      <td>0.7332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9638</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.6642</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1630</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.9498</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0250</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2788</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.7817</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0652</td>\n",
       "      <td>0.0344</td>\n",
       "      <td>0.0011</td>\n",
       "      <td>0.0213</td>\n",
       "      <td>0.0753</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0527</td>\n",
       "      <td>0.0104</td>\n",
       "      <td>0.0369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0184</td>\n",
       "      <td>0.0167</td>\n",
       "      <td>0.0003</td>\n",
       "      <td>0.0084</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0189</td>\n",
       "      <td>0.0102</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0097</td>\n",
       "      <td>0.0142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0225</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0402</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0394</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>0.0199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9122</td>\n",
       "      <td>0.9515</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9376</td>\n",
       "      <td>0.9200</td>\n",
       "      <td>0.8080</td>\n",
       "      <td>0.8745</td>\n",
       "      <td>0.7766</td>\n",
       "      <td>0.8901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8435</td>\n",
       "      <td>0.7605</td>\n",
       "      <td>0.9428</td>\n",
       "      <td>0.9672</td>\n",
       "      <td>0.9234</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9685</td>\n",
       "      <td>0.9531</td>\n",
       "      <td>0.9047</td>\n",
       "      <td>0.9586</td>\n",
       "      <td>0.9176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8765</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.9279</td>\n",
       "      <td>0.9124</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.9458</td>\n",
       "      <td>0.9436</td>\n",
       "      <td>0.8746</td>\n",
       "      <td>0.8893</td>\n",
       "      <td>0.8581</td>\n",
       "      <td>0.9007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "3   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "4   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "5   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "6         Decision Tree  precision  0.2669  0.2152  0.2530  0.2524  0.3333   \n",
       "7         Decision Tree     recall  0.5591  0.6624  0.4515  0.6045  0.5542   \n",
       "8         Decision Tree   f1-score  0.3613  0.3249  0.3242  0.3561  0.4163   \n",
       "9         Random Forest  precision  0.2926  0.2309  0.2490  0.2899  0.4845   \n",
       "10        Random Forest     recall  0.3760  0.5641  0.2658  0.4455  0.3775   \n",
       "11        Random Forest   f1-score  0.3291  0.3276  0.2571  0.3513  0.4244   \n",
       "12                  CNN  precision  0.9713  0.8047  1.0000  1.0000  0.9661   \n",
       "13                  CNN     recall  0.0189  0.1266  0.0191  0.0241  0.6106   \n",
       "14                  CNN   f1-score  0.0371  0.2187  0.0375  0.0470  0.7482   \n",
       "15         PyramidalCNN  precision  0.0000  0.8947  0.0000  0.0000  0.8926   \n",
       "16         PyramidalCNN     recall  0.0000  0.5988  0.0000  0.0000  0.8724   \n",
       "17         PyramidalCNN   f1-score  0.0000  0.7174  0.0000  0.0000  0.8824   \n",
       "18                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "19                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "20                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "21               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "22               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "23               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "24             ConvLSTM  precision  0.0000  0.9226  0.0000  0.0000  0.9640   \n",
       "25             ConvLSTM     recall  0.0000  0.5478  0.0000  0.0000  0.8461   \n",
       "26             ConvLSTM   f1-score  0.0000  0.6875  0.0000  0.0000  0.9012   \n",
       "27               EEGNet  precision  0.0000  0.0194  0.0000  0.0000  0.0000   \n",
       "28               EEGNet     recall  0.0000  0.0001  0.0000  0.0000  0.0000   \n",
       "29               EEGNet   f1-score  0.0000  0.0002  0.0000  0.0000  0.0000   \n",
       "30        InceptionTime  precision  0.5556  0.8181  1.0000  1.0000  0.8463   \n",
       "31        InceptionTime     recall  0.0056  0.7218  0.0013  0.0072  0.9310   \n",
       "32        InceptionTime   f1-score  0.0110  0.7669  0.0026  0.0143  0.8866   \n",
       "33             Xception  precision  0.0000  0.9521  0.0000  0.0000  0.9030   \n",
       "34             Xception     recall  0.0000  0.5080  0.0000  0.0000  0.8959   \n",
       "35             Xception   f1-score  0.0000  0.6625  0.0000  0.0000  0.8994   \n",
       "36                 UNet  precision  0.9916  0.8684  0.9978  0.9852  0.9704   \n",
       "37                 UNet     recall  0.4463  0.3666  0.5111  0.6851  0.7982   \n",
       "38                 UNet   f1-score  0.6156  0.5156  0.6759  0.8082  0.8760   \n",
       "39      SalientSleepNet  precision  0.0000  0.1254  0.0000  0.0000  0.9638   \n",
       "40      SalientSleepNet     recall  0.0000  0.0139  0.0000  0.0000  0.1630   \n",
       "41      SalientSleepNet   f1-score  0.0000  0.0250  0.0000  0.0000  0.2788   \n",
       "42             DETRtime  precision  0.0652  0.0344  0.0011  0.0213  0.0753   \n",
       "43             DETRtime     recall  0.0184  0.0167  0.0003  0.0084  0.0274   \n",
       "44             DETRtime   f1-score  0.0287  0.0225  0.0005  0.0121  0.0402   \n",
       "45     AugUNet1D (ours)  precision  0.9122  0.9515  0.9135  0.8635  0.9438   \n",
       "46     AugUNet1D (ours)     recall  0.8435  0.7605  0.9428  0.9672  0.9234   \n",
       "47     AugUNet1D (ours)   f1-score  0.8765  0.8454  0.9279  0.9124  0.9335   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "3   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "4   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "5   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "6   0.2500  0.3605  0.1768  0.1370  0.0922  0.2337  \n",
       "7   0.5992  0.6485  0.7475  0.6184  0.5922  0.6038  \n",
       "8   0.3528  0.4634  0.2860  0.2244  0.1595  0.3269  \n",
       "9   0.2094  0.3624  0.2017  0.1399  0.0949  0.2555  \n",
       "10  0.3207  0.3473  0.7178  0.5217  0.4749  0.4411  \n",
       "11  0.2533  0.3547  0.3149  0.2206  0.1581  0.2991  \n",
       "12  0.8741  0.8650  0.7385  0.8322  1.0000  0.9052  \n",
       "13  0.8251  0.7886  0.9287  0.6642  0.0095  0.4015  \n",
       "14  0.8489  0.8251  0.8227  0.7387  0.0189  0.4343  \n",
       "15  0.8170  0.7826  0.7631  0.7779  0.0000  0.4928  \n",
       "16  0.9243  0.9462  0.9221  0.8192  0.0000  0.5083  \n",
       "17  0.8673  0.8567  0.8351  0.7980  0.0000  0.4957  \n",
       "18  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "19  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "20  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "21  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "22  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "23  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "24  0.9510  0.9378  0.8617  0.9352  0.0000  0.5572  \n",
       "25  0.6807  0.7287  0.8723  0.5975  0.0000  0.4273  \n",
       "26  0.7935  0.8201  0.8670  0.7291  0.0000  0.4798  \n",
       "27  0.0000  0.0000  0.7489  0.0000  0.0000  0.0768  \n",
       "28  0.0000  0.0000  0.7233  0.0000  0.0000  0.0723  \n",
       "29  0.0000  0.0000  0.7358  0.0000  0.0000  0.0736  \n",
       "30  0.8644  0.8160  0.7392  0.7983  1.0000  0.8438  \n",
       "31  0.8538  0.9039  0.9111  0.7807  0.0070  0.5123  \n",
       "32  0.8591  0.8577  0.8162  0.7894  0.0139  0.5018  \n",
       "33  0.8710  0.8344  0.7627  0.8091  0.0000  0.5132  \n",
       "34  0.9219  0.9400  0.9548  0.8494  0.0000  0.5070  \n",
       "35  0.8958  0.8841  0.8480  0.8288  0.0000  0.5019  \n",
       "36  0.9626  0.9407  0.4412  0.9461  0.9644  0.9068  \n",
       "37  0.7626  0.8116  0.9898  0.6470  0.5994  0.6618  \n",
       "38  0.8510  0.8714  0.6103  0.7685  0.7393  0.7332  \n",
       "39  0.0000  1.0000  0.6642  0.0000  0.0000  0.2753  \n",
       "40  0.0000  0.0031  0.9498  0.0000  0.0000  0.1130  \n",
       "41  0.0000  0.0061  0.7817  0.0000  0.0000  0.1092  \n",
       "42  0.0758  0.0326  0.0000  0.0527  0.0104  0.0369  \n",
       "43  0.0189  0.0102  0.0000  0.0315  0.0097  0.0142  \n",
       "44  0.0303  0.0155  0.0000  0.0394  0.0100  0.0199  \n",
       "45  0.9376  0.9200  0.8080  0.8745  0.7766  0.8901  \n",
       "46  0.9541  0.9685  0.9531  0.9047  0.9586  0.9176  \n",
       "47  0.9458  0.9436  0.8746  0.8893  0.8581  0.9007  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3fbacfd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.2314</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3702</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>0.4204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9038</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9002</td>\n",
       "      <td>0.9051</td>\n",
       "      <td>0.8528</td>\n",
       "      <td>0.7905</td>\n",
       "      <td>0.8489</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.2828</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.8350</td>\n",
       "      <td>0.7973</td>\n",
       "      <td>0.8681</td>\n",
       "      <td>0.8940</td>\n",
       "      <td>0.7292</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0077</td>\n",
       "      <td>0.4308</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.8664</td>\n",
       "      <td>0.8478</td>\n",
       "      <td>0.8604</td>\n",
       "      <td>0.8391</td>\n",
       "      <td>0.7845</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9979</td>\n",
       "      <td>0.8683</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8393</td>\n",
       "      <td>0.7975</td>\n",
       "      <td>0.7674</td>\n",
       "      <td>0.6943</td>\n",
       "      <td>0.7546</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.1635</td>\n",
       "      <td>0.6919</td>\n",
       "      <td>0.0039</td>\n",
       "      <td>0.1638</td>\n",
       "      <td>0.9438</td>\n",
       "      <td>0.9636</td>\n",
       "      <td>0.9748</td>\n",
       "      <td>0.9679</td>\n",
       "      <td>0.8910</td>\n",
       "      <td>0.0214</td>\n",
       "      <td>0.5786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2809</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>0.0078</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.8885</td>\n",
       "      <td>0.8727</td>\n",
       "      <td>0.8587</td>\n",
       "      <td>0.8086</td>\n",
       "      <td>0.8172</td>\n",
       "      <td>0.0420</td>\n",
       "      <td>0.5628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9560</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>0.9772</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.8143</td>\n",
       "      <td>0.9592</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5207</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.8934</td>\n",
       "      <td>0.7990</td>\n",
       "      <td>0.8823</td>\n",
       "      <td>0.9282</td>\n",
       "      <td>0.7230</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6742</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0005</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>0.8792</td>\n",
       "      <td>0.9152</td>\n",
       "      <td>0.8675</td>\n",
       "      <td>0.8245</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7868</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9273</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.6468</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8855</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8682</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3156</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9059</td>\n",
       "      <td>0.1023</td>\n",
       "      <td>0.1266</td>\n",
       "      <td>0.7413</td>\n",
       "      <td>0.0595</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9407</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9175</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>0.8569</td>\n",
       "      <td>0.6942</td>\n",
       "      <td>0.8397</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.8143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0057</td>\n",
       "      <td>0.4757</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0032</td>\n",
       "      <td>0.8631</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.9102</td>\n",
       "      <td>0.9581</td>\n",
       "      <td>0.7727</td>\n",
       "      <td>0.0031</td>\n",
       "      <td>0.4856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0113</td>\n",
       "      <td>0.6319</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0064</td>\n",
       "      <td>0.8894</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.8828</td>\n",
       "      <td>0.8051</td>\n",
       "      <td>0.8048</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.4917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.9323</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0502</td>\n",
       "      <td>0.9119</td>\n",
       "      <td>0.8990</td>\n",
       "      <td>0.8698</td>\n",
       "      <td>0.6912</td>\n",
       "      <td>0.8717</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.5347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9309</td>\n",
       "      <td>0.6119</td>\n",
       "      <td>0.9334</td>\n",
       "      <td>0.9377</td>\n",
       "      <td>0.9254</td>\n",
       "      <td>0.9213</td>\n",
       "      <td>0.9524</td>\n",
       "      <td>0.9768</td>\n",
       "      <td>0.8184</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.8917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.7389</td>\n",
       "      <td>0.1100</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.9186</td>\n",
       "      <td>0.9100</td>\n",
       "      <td>0.9092</td>\n",
       "      <td>0.8095</td>\n",
       "      <td>0.8442</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.5455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9905</td>\n",
       "      <td>0.9650</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0.9358</td>\n",
       "      <td>0.9734</td>\n",
       "      <td>0.9463</td>\n",
       "      <td>0.6259</td>\n",
       "      <td>0.9480</td>\n",
       "      <td>0.9622</td>\n",
       "      <td>0.9339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.2470</td>\n",
       "      <td>0.4116</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.3434</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.7542</td>\n",
       "      <td>0.8281</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.6970</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.5373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3954</td>\n",
       "      <td>0.5770</td>\n",
       "      <td>0.1422</td>\n",
       "      <td>0.5106</td>\n",
       "      <td>0.9218</td>\n",
       "      <td>0.8499</td>\n",
       "      <td>0.8833</td>\n",
       "      <td>0.7652</td>\n",
       "      <td>0.8034</td>\n",
       "      <td>0.2174</td>\n",
       "      <td>0.6066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8137</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8132</td>\n",
       "      <td>0.8200</td>\n",
       "      <td>0.7690</td>\n",
       "      <td>0.6735</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6146</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9319</td>\n",
       "      <td>0.9206</td>\n",
       "      <td>0.9471</td>\n",
       "      <td>0.9529</td>\n",
       "      <td>0.7981</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7003</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8685</td>\n",
       "      <td>0.8674</td>\n",
       "      <td>0.8488</td>\n",
       "      <td>0.7892</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.9037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.9402</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "3   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "4   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "5   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "6         Decision Tree  precision  0.2706  0.2184  0.2442  0.2573  0.3310   \n",
       "7         Decision Tree     recall  0.5624  0.6616  0.4430  0.6045  0.5622   \n",
       "8         Decision Tree   f1-score  0.3654  0.3283  0.3148  0.3609  0.4167   \n",
       "9         Random Forest  precision  0.2811  0.2247  0.2290  0.2801  0.4742   \n",
       "10        Random Forest     recall  0.3702  0.5471  0.2532  0.4227  0.3695   \n",
       "11        Random Forest   f1-score  0.3196  0.3186  0.2405  0.3370  0.4153   \n",
       "12                  CNN  precision  1.0000  0.9038  1.0000  1.0000  0.9002   \n",
       "13                  CNN     recall  0.0039  0.2828  0.0010  0.0047  0.8350   \n",
       "14                  CNN   f1-score  0.0077  0.4308  0.0019  0.0093  0.8664   \n",
       "15         PyramidalCNN  precision  0.9979  0.8683  1.0000  1.0000  0.8393   \n",
       "16         PyramidalCNN     recall  0.1635  0.6919  0.0039  0.1638  0.9438   \n",
       "17         PyramidalCNN   f1-score  0.2809  0.7701  0.0078  0.2815  0.8885   \n",
       "18                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "19                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "20                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "21               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "22               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "23               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "24             ConvLSTM  precision  0.0000  0.9560  0.0000  1.0000  0.9731   \n",
       "25             ConvLSTM     recall  0.0000  0.5207  0.0000  0.0002  0.8934   \n",
       "26             ConvLSTM   f1-score  0.0000  0.6742  0.0000  0.0005  0.9316   \n",
       "27               EEGNet  precision  0.0000  0.7868  0.0000  0.0000  0.9273   \n",
       "28               EEGNet     recall  0.0000  0.1974  0.0000  0.0000  0.8855   \n",
       "29               EEGNet   f1-score  0.0000  0.3156  0.0000  0.0000  0.9059   \n",
       "30        InceptionTime  precision  1.0000  0.9407  0.0000  1.0000  0.9175   \n",
       "31        InceptionTime     recall  0.0057  0.4757  0.0000  0.0032  0.8631   \n",
       "32        InceptionTime   f1-score  0.0113  0.6319  0.0000  0.0064  0.8894   \n",
       "33             Xception  precision  0.0485  0.9323  0.0584  0.0502  0.9119   \n",
       "34             Xception     recall  0.9309  0.6119  0.9334  0.9377  0.9254   \n",
       "35             Xception   f1-score  0.0922  0.7389  0.1100  0.0953  0.9186   \n",
       "36                 UNet  precision  0.9905  0.9650  0.9968  0.9949  0.9358   \n",
       "37                 UNet     recall  0.2470  0.4116  0.0765  0.3434  0.9081   \n",
       "38                 UNet   f1-score  0.3954  0.5770  0.1422  0.5106  0.9218   \n",
       "39      SalientSleepNet  precision  0.0000  0.8137  0.0000  0.0000  0.8132   \n",
       "40      SalientSleepNet     recall  0.0000  0.6146  0.0000  0.0000  0.9319   \n",
       "41      SalientSleepNet   f1-score  0.0000  0.7003  0.0000  0.0000  0.8685   \n",
       "42             DETRtime  precision  0.0561  0.0556  0.0779  0.0586  0.0642   \n",
       "43             DETRtime     recall  0.5345  0.4944  0.5862  0.5299  0.4926   \n",
       "44             DETRtime   f1-score  0.1016  0.0999  0.1374  0.1055  0.1136   \n",
       "45     AugUNet1D (ours)  precision  0.9037  0.9465  0.9127  0.8593  0.9792   \n",
       "46     AugUNet1D (ours)     recall  0.8444  0.5948  0.9402  0.9700  0.8826   \n",
       "47     AugUNet1D (ours)   f1-score  0.8730  0.7305  0.9262  0.9113  0.9284   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "3   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "4   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "5   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "6   0.2540  0.3581  0.1782  0.1421  0.0910  0.2345  \n",
       "7   0.6034  0.6444  0.7673  0.6232  0.5866  0.6059  \n",
       "8   0.3575  0.4604  0.2892  0.2314  0.1575  0.3282  \n",
       "9   0.2060  0.3565  0.1978  0.1182  0.0847  0.2452  \n",
       "10  0.3207  0.3431  0.7129  0.4396  0.4246  0.4204  \n",
       "11  0.2508  0.3497  0.3097  0.1863  0.1413  0.2869  \n",
       "12  0.9051  0.8528  0.7905  0.8489  0.0000  0.8201  \n",
       "13  0.7973  0.8681  0.8940  0.7292  0.0000  0.4416  \n",
       "14  0.8478  0.8604  0.8391  0.7845  0.0000  0.4648  \n",
       "15  0.7975  0.7674  0.6943  0.7546  1.0000  0.8719  \n",
       "16  0.9636  0.9748  0.9679  0.8910  0.0214  0.5786  \n",
       "17  0.8727  0.8587  0.8086  0.8172  0.0420  0.5628  \n",
       "18  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "19  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "20  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "21  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "22  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "23  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "24  0.9772  0.9506  0.8143  0.9592  0.0000  0.6630  \n",
       "25  0.7990  0.8823  0.9282  0.7230  0.0000  0.4747  \n",
       "26  0.8792  0.9152  0.8675  0.8245  0.0000  0.5093  \n",
       "27  0.0539  0.0676  0.6468  0.0307  0.0000  0.2513  \n",
       "28  0.9872  1.0000  0.8682  1.0000  0.0000  0.4938  \n",
       "29  0.1023  0.1266  0.7413  0.0595  0.0000  0.2251  \n",
       "30  0.8942  0.8569  0.6942  0.8397  1.0000  0.8143  \n",
       "31  0.8645  0.9102  0.9581  0.7727  0.0031  0.4856  \n",
       "32  0.8791  0.8828  0.8051  0.8048  0.0061  0.4917  \n",
       "33  0.8990  0.8698  0.6912  0.8717  0.0139  0.5347  \n",
       "34  0.9213  0.9524  0.9768  0.8184  0.9092  0.8917  \n",
       "35  0.9100  0.9092  0.8095  0.8442  0.0275  0.5455  \n",
       "36  0.9734  0.9463  0.6259  0.9480  0.9622  0.9339  \n",
       "37  0.7542  0.8281  0.9842  0.6970  0.1225  0.5373  \n",
       "38  0.8499  0.8833  0.7652  0.8034  0.2174  0.6066  \n",
       "39  0.8200  0.7690  0.6735  0.7704  0.0000  0.4660  \n",
       "40  0.9206  0.9471  0.9529  0.7981  0.0000  0.5165  \n",
       "41  0.8674  0.8488  0.7892  0.7840  0.0000  0.4858  \n",
       "42  0.0770  0.0885  0.0367  0.0355  0.0145  0.0565  \n",
       "43  0.5911  0.5440  0.4746  0.5215  0.4963  0.5265  \n",
       "44  0.1363  0.1522  0.0681  0.0665  0.0282  0.1009  \n",
       "45  0.9525  0.9518  0.8421  0.9194  0.7697  0.9037  \n",
       "46  0.9475  0.9546  0.9466  0.8867  0.9604  0.8928  \n",
       "47  0.9500  0.9532  0.8913  0.9027  0.8545  0.8921  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "59c5314e-c2a4-4ec3-8fa2-082695be1463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Metric</th>\n",
       "      <th>M1</th>\n",
       "      <th>M2</th>\n",
       "      <th>M3</th>\n",
       "      <th>M4</th>\n",
       "      <th>M5</th>\n",
       "      <th>M6</th>\n",
       "      <th>M7</th>\n",
       "      <th>M8</th>\n",
       "      <th>M9</th>\n",
       "      <th>M10</th>\n",
       "      <th>avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0867</td>\n",
       "      <td>0.0902</td>\n",
       "      <td>0.0994</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1105</td>\n",
       "      <td>0.1028</td>\n",
       "      <td>0.1249</td>\n",
       "      <td>0.0686</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.0868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.9759</td>\n",
       "      <td>0.9605</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.9818</td>\n",
       "      <td>0.9719</td>\n",
       "      <td>0.9831</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.9802</td>\n",
       "      <td>0.9758</td>\n",
       "      <td>0.9888</td>\n",
       "      <td>0.9759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.1802</td>\n",
       "      <td>0.1597</td>\n",
       "      <td>0.1984</td>\n",
       "      <td>0.1861</td>\n",
       "      <td>0.2214</td>\n",
       "      <td>0.1282</td>\n",
       "      <td>0.1231</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.1529</td>\n",
       "      <td>0.1935</td>\n",
       "      <td>0.1442</td>\n",
       "      <td>0.1490</td>\n",
       "      <td>0.2592</td>\n",
       "      <td>0.1678</td>\n",
       "      <td>0.2493</td>\n",
       "      <td>0.1306</td>\n",
       "      <td>0.1014</td>\n",
       "      <td>0.0570</td>\n",
       "      <td>0.1605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.7030</td>\n",
       "      <td>0.8340</td>\n",
       "      <td>0.6582</td>\n",
       "      <td>0.7909</td>\n",
       "      <td>0.8193</td>\n",
       "      <td>0.7511</td>\n",
       "      <td>0.7113</td>\n",
       "      <td>0.8861</td>\n",
       "      <td>0.7585</td>\n",
       "      <td>0.8324</td>\n",
       "      <td>0.7745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.2512</td>\n",
       "      <td>0.3142</td>\n",
       "      <td>0.2365</td>\n",
       "      <td>0.2507</td>\n",
       "      <td>0.3938</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.3692</td>\n",
       "      <td>0.2276</td>\n",
       "      <td>0.1788</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2706</td>\n",
       "      <td>0.2184</td>\n",
       "      <td>0.2442</td>\n",
       "      <td>0.2573</td>\n",
       "      <td>0.3310</td>\n",
       "      <td>0.2540</td>\n",
       "      <td>0.3581</td>\n",
       "      <td>0.1782</td>\n",
       "      <td>0.1421</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.2345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5624</td>\n",
       "      <td>0.6616</td>\n",
       "      <td>0.4430</td>\n",
       "      <td>0.6045</td>\n",
       "      <td>0.5622</td>\n",
       "      <td>0.6034</td>\n",
       "      <td>0.6444</td>\n",
       "      <td>0.7673</td>\n",
       "      <td>0.6232</td>\n",
       "      <td>0.5866</td>\n",
       "      <td>0.6059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3654</td>\n",
       "      <td>0.3283</td>\n",
       "      <td>0.3148</td>\n",
       "      <td>0.3609</td>\n",
       "      <td>0.4167</td>\n",
       "      <td>0.3575</td>\n",
       "      <td>0.4604</td>\n",
       "      <td>0.2892</td>\n",
       "      <td>0.2314</td>\n",
       "      <td>0.1575</td>\n",
       "      <td>0.3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.2811</td>\n",
       "      <td>0.2247</td>\n",
       "      <td>0.2290</td>\n",
       "      <td>0.2801</td>\n",
       "      <td>0.4742</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.3565</td>\n",
       "      <td>0.1978</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0847</td>\n",
       "      <td>0.2452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.3702</td>\n",
       "      <td>0.5471</td>\n",
       "      <td>0.2532</td>\n",
       "      <td>0.4227</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.3207</td>\n",
       "      <td>0.3431</td>\n",
       "      <td>0.7129</td>\n",
       "      <td>0.4396</td>\n",
       "      <td>0.4246</td>\n",
       "      <td>0.4204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.3196</td>\n",
       "      <td>0.3186</td>\n",
       "      <td>0.2405</td>\n",
       "      <td>0.3370</td>\n",
       "      <td>0.4153</td>\n",
       "      <td>0.2508</td>\n",
       "      <td>0.3497</td>\n",
       "      <td>0.3097</td>\n",
       "      <td>0.1863</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8595</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.9081</td>\n",
       "      <td>0.8641</td>\n",
       "      <td>0.7518</td>\n",
       "      <td>0.8596</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6818</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8968</td>\n",
       "      <td>0.7351</td>\n",
       "      <td>0.8041</td>\n",
       "      <td>0.8942</td>\n",
       "      <td>0.6743</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7604</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8822</td>\n",
       "      <td>0.8125</td>\n",
       "      <td>0.8330</td>\n",
       "      <td>0.8168</td>\n",
       "      <td>0.7558</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9998</td>\n",
       "      <td>0.8874</td>\n",
       "      <td>0.9916</td>\n",
       "      <td>0.8995</td>\n",
       "      <td>0.8814</td>\n",
       "      <td>0.8951</td>\n",
       "      <td>0.8354</td>\n",
       "      <td>0.7440</td>\n",
       "      <td>0.8454</td>\n",
       "      <td>0.7588</td>\n",
       "      <td>0.8738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0197</td>\n",
       "      <td>0.5870</td>\n",
       "      <td>0.0133</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.9310</td>\n",
       "      <td>0.8714</td>\n",
       "      <td>0.9276</td>\n",
       "      <td>0.9091</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.5118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.7066</td>\n",
       "      <td>0.0262</td>\n",
       "      <td>0.0862</td>\n",
       "      <td>0.9055</td>\n",
       "      <td>0.8831</td>\n",
       "      <td>0.8791</td>\n",
       "      <td>0.8183</td>\n",
       "      <td>0.8214</td>\n",
       "      <td>0.0295</td>\n",
       "      <td>0.5195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9976</td>\n",
       "      <td>0.9372</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>0.9395</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>0.9872</td>\n",
       "      <td>0.7918</td>\n",
       "      <td>0.9882</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0359</td>\n",
       "      <td>0.5772</td>\n",
       "      <td>0.0013</td>\n",
       "      <td>0.0506</td>\n",
       "      <td>0.9046</td>\n",
       "      <td>0.0996</td>\n",
       "      <td>0.4147</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.2874</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0692</td>\n",
       "      <td>0.7144</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.0963</td>\n",
       "      <td>0.9217</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.5841</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.4453</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0468</td>\n",
       "      <td>0.7365</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0385</td>\n",
       "      <td>0.0592</td>\n",
       "      <td>0.0442</td>\n",
       "      <td>0.3900</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0141</td>\n",
       "      <td>0.1459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.2551</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.0897</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.9388</td>\n",
       "      <td>0.0654</td>\n",
       "      <td>0.0685</td>\n",
       "      <td>0.1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.3789</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.0621</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0772</td>\n",
       "      <td>0.0496</td>\n",
       "      <td>0.5511</td>\n",
       "      <td>0.0314</td>\n",
       "      <td>0.0233</td>\n",
       "      <td>0.1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9316</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.9775</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.7324</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.3443</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.7667</td>\n",
       "      <td>0.8408</td>\n",
       "      <td>0.8466</td>\n",
       "      <td>0.9023</td>\n",
       "      <td>0.7447</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5028</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8594</td>\n",
       "      <td>0.8704</td>\n",
       "      <td>0.8667</td>\n",
       "      <td>0.8085</td>\n",
       "      <td>0.8027</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Xception</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.8449</td>\n",
       "      <td>0.8926</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8276</td>\n",
       "      <td>0.8703</td>\n",
       "      <td>0.8859</td>\n",
       "      <td>0.8692</td>\n",
       "      <td>0.7420</td>\n",
       "      <td>0.8759</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.6808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Xception</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.7021</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0044</td>\n",
       "      <td>0.9555</td>\n",
       "      <td>0.9375</td>\n",
       "      <td>0.9659</td>\n",
       "      <td>0.9135</td>\n",
       "      <td>0.8406</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Xception</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0052</td>\n",
       "      <td>0.7860</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0088</td>\n",
       "      <td>0.9109</td>\n",
       "      <td>0.9110</td>\n",
       "      <td>0.9150</td>\n",
       "      <td>0.8189</td>\n",
       "      <td>0.8579</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>UNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.5355</td>\n",
       "      <td>0.0560</td>\n",
       "      <td>0.3735</td>\n",
       "      <td>0.5700</td>\n",
       "      <td>0.8916</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0.9335</td>\n",
       "      <td>0.5433</td>\n",
       "      <td>0.9506</td>\n",
       "      <td>0.3037</td>\n",
       "      <td>0.6112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>UNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0347</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.0950</td>\n",
       "      <td>0.7912</td>\n",
       "      <td>0.5678</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>0.8842</td>\n",
       "      <td>0.4436</td>\n",
       "      <td>0.0195</td>\n",
       "      <td>0.3630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>UNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0651</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.8385</td>\n",
       "      <td>0.7120</td>\n",
       "      <td>0.6979</td>\n",
       "      <td>0.6730</td>\n",
       "      <td>0.6050</td>\n",
       "      <td>0.0366</td>\n",
       "      <td>0.3933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.5792</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8636</td>\n",
       "      <td>0.8877</td>\n",
       "      <td>0.8285</td>\n",
       "      <td>0.7122</td>\n",
       "      <td>0.8309</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0470</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8974</td>\n",
       "      <td>0.8747</td>\n",
       "      <td>0.9241</td>\n",
       "      <td>0.9185</td>\n",
       "      <td>0.7735</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.8802</td>\n",
       "      <td>0.8812</td>\n",
       "      <td>0.8737</td>\n",
       "      <td>0.8023</td>\n",
       "      <td>0.8011</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0779</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0642</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0885</td>\n",
       "      <td>0.0367</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.0145</td>\n",
       "      <td>0.0565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.5345</td>\n",
       "      <td>0.4944</td>\n",
       "      <td>0.5862</td>\n",
       "      <td>0.5299</td>\n",
       "      <td>0.4926</td>\n",
       "      <td>0.5911</td>\n",
       "      <td>0.5440</td>\n",
       "      <td>0.4746</td>\n",
       "      <td>0.5215</td>\n",
       "      <td>0.4963</td>\n",
       "      <td>0.5265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.1016</td>\n",
       "      <td>0.0999</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.1136</td>\n",
       "      <td>0.1363</td>\n",
       "      <td>0.1522</td>\n",
       "      <td>0.0681</td>\n",
       "      <td>0.0665</td>\n",
       "      <td>0.0282</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>precision</td>\n",
       "      <td>0.9037</td>\n",
       "      <td>0.9465</td>\n",
       "      <td>0.9127</td>\n",
       "      <td>0.8593</td>\n",
       "      <td>0.9792</td>\n",
       "      <td>0.9525</td>\n",
       "      <td>0.9518</td>\n",
       "      <td>0.8421</td>\n",
       "      <td>0.9194</td>\n",
       "      <td>0.7697</td>\n",
       "      <td>0.9037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>recall</td>\n",
       "      <td>0.8444</td>\n",
       "      <td>0.5948</td>\n",
       "      <td>0.9402</td>\n",
       "      <td>0.9700</td>\n",
       "      <td>0.8826</td>\n",
       "      <td>0.9475</td>\n",
       "      <td>0.9546</td>\n",
       "      <td>0.9466</td>\n",
       "      <td>0.8867</td>\n",
       "      <td>0.9604</td>\n",
       "      <td>0.8928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>f1-score</td>\n",
       "      <td>0.8730</td>\n",
       "      <td>0.7305</td>\n",
       "      <td>0.9262</td>\n",
       "      <td>0.9113</td>\n",
       "      <td>0.9284</td>\n",
       "      <td>0.9500</td>\n",
       "      <td>0.9532</td>\n",
       "      <td>0.8913</td>\n",
       "      <td>0.9027</td>\n",
       "      <td>0.8545</td>\n",
       "      <td>0.8921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier     Metric      M1      M2      M3      M4      M5  \\\n",
       "0   Logistic Regression  precision  0.0867  0.0902  0.0994  0.0869  0.1105   \n",
       "1   Logistic Regression     recall  0.9759  0.9605  0.9662  0.9818  0.9719   \n",
       "2   Logistic Regression   f1-score  0.1593  0.1650  0.1802  0.1597  0.1984   \n",
       "3   K-Nearest Neighbors  precision  0.1529  0.1935  0.1442  0.1490  0.2592   \n",
       "4   K-Nearest Neighbors     recall  0.7030  0.8340  0.6582  0.7909  0.8193   \n",
       "5   K-Nearest Neighbors   f1-score  0.2512  0.3142  0.2365  0.2507  0.3938   \n",
       "6         Decision Tree  precision  0.2706  0.2184  0.2442  0.2573  0.3310   \n",
       "7         Decision Tree     recall  0.5624  0.6616  0.4430  0.6045  0.5622   \n",
       "8         Decision Tree   f1-score  0.3654  0.3283  0.3148  0.3609  0.4167   \n",
       "9         Random Forest  precision  0.2811  0.2247  0.2290  0.2801  0.4742   \n",
       "10        Random Forest     recall  0.3702  0.5471  0.2532  0.4227  0.3695   \n",
       "11        Random Forest   f1-score  0.3196  0.3186  0.2405  0.3370  0.4153   \n",
       "12                  CNN  precision  0.0000  0.8595  0.0000  0.0000  0.8680   \n",
       "13                  CNN     recall  0.0000  0.6818  0.0000  0.0000  0.8968   \n",
       "14                  CNN   f1-score  0.0000  0.7604  0.0000  0.0000  0.8822   \n",
       "15         PyramidalCNN  precision  0.9998  0.8874  0.9916  0.8995  0.8814   \n",
       "16         PyramidalCNN     recall  0.0197  0.5870  0.0133  0.0453  0.9310   \n",
       "17         PyramidalCNN   f1-score  0.0387  0.7066  0.0262  0.0862  0.9055   \n",
       "18                 LSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "19                 LSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "20                 LSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "21               biLSTM  precision  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "22               biLSTM     recall  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "23               biLSTM   f1-score  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
       "24             ConvLSTM  precision  0.9976  0.9372  1.0000  1.0000  0.9395   \n",
       "25             ConvLSTM     recall  0.0359  0.5772  0.0013  0.0506  0.9046   \n",
       "26             ConvLSTM   f1-score  0.0692  0.7144  0.0026  0.0963  0.9217   \n",
       "27               EEGNet  precision  0.0468  0.7365  0.0616  0.0475  0.0385   \n",
       "28               EEGNet     recall  0.0640  0.2551  0.0937  0.0897  0.0345   \n",
       "29               EEGNet   f1-score  0.0541  0.3789  0.0743  0.0621  0.0364   \n",
       "30        InceptionTime  precision  0.0000  0.9316  0.0000  0.0000  0.9775   \n",
       "31        InceptionTime     recall  0.0000  0.3443  0.0000  0.0000  0.7667   \n",
       "32        InceptionTime   f1-score  0.0000  0.5028  0.0000  0.0000  0.8594   \n",
       "33             Xception  precision  0.8449  0.8926  0.0000  0.8276  0.8703   \n",
       "34             Xception     recall  0.0026  0.7021  0.0000  0.0044  0.9555   \n",
       "35             Xception   f1-score  0.0052  0.7860  0.0000  0.0088  0.9109   \n",
       "36                 UNet  precision  0.5355  0.0560  0.3735  0.5700  0.8916   \n",
       "37                 UNet     recall  0.0347  0.2069  0.0294  0.0950  0.7912   \n",
       "38                 UNet   f1-score  0.0651  0.0881  0.0544  0.1628  0.8385   \n",
       "39      SalientSleepNet  precision  0.0000  0.5792  0.0000  0.0000  0.8636   \n",
       "40      SalientSleepNet     recall  0.0000  0.0470  0.0000  0.0000  0.8974   \n",
       "41      SalientSleepNet   f1-score  0.0000  0.0870  0.0000  0.0000  0.8802   \n",
       "42             DETRtime  precision  0.0561  0.0556  0.0779  0.0586  0.0642   \n",
       "43             DETRtime     recall  0.5345  0.4944  0.5862  0.5299  0.4926   \n",
       "44             DETRtime   f1-score  0.1016  0.0999  0.1374  0.1055  0.1136   \n",
       "45     AugUNet1D (ours)  precision  0.9037  0.9465  0.9127  0.8593  0.9792   \n",
       "46     AugUNet1D (ours)     recall  0.8444  0.5948  0.9402  0.9700  0.8826   \n",
       "47     AugUNet1D (ours)   f1-score  0.8730  0.7305  0.9262  0.9113  0.9284   \n",
       "\n",
       "        M6      M7      M8      M9     M10     avg  \n",
       "0   0.1028  0.1249  0.0686  0.0657  0.0325  0.0868  \n",
       "1   0.9831  0.9749  0.9802  0.9758  0.9888  0.9759  \n",
       "2   0.1861  0.2214  0.1282  0.1231  0.0629  0.1584  \n",
       "3   0.1678  0.2493  0.1306  0.1014  0.0570  0.1605  \n",
       "4   0.7511  0.7113  0.8861  0.7585  0.8324  0.7745  \n",
       "5   0.2743  0.3692  0.2276  0.1788  0.1067  0.2603  \n",
       "6   0.2540  0.3581  0.1782  0.1421  0.0910  0.2345  \n",
       "7   0.6034  0.6444  0.7673  0.6232  0.5866  0.6059  \n",
       "8   0.3575  0.4604  0.2892  0.2314  0.1575  0.3282  \n",
       "9   0.2060  0.3565  0.1978  0.1182  0.0847  0.2452  \n",
       "10  0.3207  0.3431  0.7129  0.4396  0.4246  0.4204  \n",
       "11  0.2508  0.3497  0.3097  0.1863  0.1413  0.2869  \n",
       "12  0.9081  0.8641  0.7518  0.8596  0.0000  0.5111  \n",
       "13  0.7351  0.8041  0.8942  0.6743  0.0000  0.4686  \n",
       "14  0.8125  0.8330  0.8168  0.7558  0.0000  0.4861  \n",
       "15  0.8951  0.8354  0.7440  0.8454  0.7588  0.8738  \n",
       "16  0.8714  0.9276  0.9091  0.7987  0.0151  0.5118  \n",
       "17  0.8831  0.8791  0.8183  0.8214  0.0295  0.5195  \n",
       "18  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "19  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "20  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "21  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "22  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "23  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  \n",
       "24  0.9980  0.9872  0.7918  0.9882  0.0000  0.8640  \n",
       "25  0.0996  0.4147  0.9660  0.2874  0.0000  0.3337  \n",
       "26  0.1812  0.5841  0.8703  0.4453  0.0000  0.3885  \n",
       "27  0.0592  0.0442  0.3900  0.0207  0.0141  0.1459  \n",
       "28  0.1109  0.0565  0.9388  0.0654  0.0685  0.1777  \n",
       "29  0.0772  0.0496  0.5511  0.0314  0.0233  0.1338  \n",
       "30  0.9023  0.8877  0.7324  0.8704  0.0000  0.5302  \n",
       "31  0.8408  0.8466  0.9023  0.7447  0.0000  0.4445  \n",
       "32  0.8704  0.8667  0.8085  0.8027  0.0000  0.4711  \n",
       "33  0.8859  0.8692  0.7420  0.8759  0.0000  0.6808  \n",
       "34  0.9375  0.9659  0.9135  0.8406  0.0000  0.5322  \n",
       "35  0.9110  0.9150  0.8189  0.8579  0.0000  0.5214  \n",
       "36  0.9544  0.9335  0.5433  0.9506  0.3037  0.6112  \n",
       "37  0.5678  0.5572  0.8842  0.4436  0.0195  0.3630  \n",
       "38  0.7120  0.6979  0.6730  0.6050  0.0366  0.3933  \n",
       "39  0.8877  0.8285  0.7122  0.8309  0.0000  0.4702  \n",
       "40  0.8747  0.9241  0.9185  0.7735  0.0000  0.4435  \n",
       "41  0.8812  0.8737  0.8023  0.8011  0.0000  0.4326  \n",
       "42  0.0770  0.0885  0.0367  0.0355  0.0145  0.0565  \n",
       "43  0.5911  0.5440  0.4746  0.5215  0.4963  0.5265  \n",
       "44  0.1363  0.1522  0.0681  0.0665  0.0282  0.1009  \n",
       "45  0.9525  0.9518  0.8421  0.9194  0.7697  0.9037  \n",
       "46  0.9475  0.9546  0.9466  0.8867  0.9604  0.8928  \n",
       "47  0.9500  0.9532  0.8913  0.9027  0.8545  0.8921  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd994a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v1=v1[v1.Metric=='f1-score'][['Classifier','avg']]\n",
    "v2=v2[v2.Metric=='f1-score'][['Classifier','avg']]\n",
    "v3=v3[v3.Metric=='f1-score'][['Classifier','avg']]\n",
    "v4=v4[v4.Metric=='f1-score'][['Classifier','avg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3ff48383-7e42-4392-80be-dd999e86885f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>avg_f1_run1</th>\n",
       "      <th>avg_f1_run2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.3269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2820</td>\n",
       "      <td>0.2991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.4343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.4957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.4798</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>0.2652</td>\n",
       "      <td>0.0736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Xception</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.5019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UNet</td>\n",
       "      <td>0.4299</td>\n",
       "      <td>0.7332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.1092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.9007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier  avg_f1_run1  avg_f1_run2\n",
       "0   Logistic Regression       0.1584       0.1584\n",
       "1   K-Nearest Neighbors       0.2603       0.2603\n",
       "2         Decision Tree       0.3289       0.3269\n",
       "3         Random Forest       0.2820       0.2991\n",
       "4                   CNN       0.4976       0.4343\n",
       "5          PyramidalCNN       0.5322       0.4957\n",
       "6                  LSTM       0.0000       0.0000\n",
       "7                biLSTM       0.0000       0.0000\n",
       "8              ConvLSTM       0.4994       0.4798\n",
       "9                EEGNet       0.2652       0.0736\n",
       "10        InceptionTime       0.5466       0.5018\n",
       "11             Xception       0.5209       0.5019\n",
       "12                 UNet       0.4299       0.7332\n",
       "13      SalientSleepNet       0.8203       0.1092\n",
       "14             DETRtime       0.0806       0.0199\n",
       "15     AugUNet1D (ours)       0.9009       0.9007"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_all=v1.rename(columns={'avg':'avg_f1_run1'}).merge(v2.rename(columns={'avg':'avg_f1_run2'}),on='Classifier')\n",
    "v_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0a0a77-28c2-4796-8a42-578da47f497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_all=v_all.merge(v3.rename(columns={'avg':'avg_f1_run3'}),on='Classifier')\n",
    "v_all=v_all.merge(v4.rename(columns={'avg':'avg_f1_run4'}),on='Classifier')\n",
    "v_all.to_csv('all_avg_f1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f353469",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>avg_f1_run1</th>\n",
       "      <th>avg_f1_run2</th>\n",
       "      <th>avg_f1_run3</th>\n",
       "      <th>avg_f1_run4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1584</td>\n",
       "      <td>0.1584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>K-Nearest Neighbors</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.2603</td>\n",
       "      <td>0.2603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.3289</td>\n",
       "      <td>0.3269</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.3282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.2820</td>\n",
       "      <td>0.2991</td>\n",
       "      <td>0.2869</td>\n",
       "      <td>0.2869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CNN</td>\n",
       "      <td>0.4976</td>\n",
       "      <td>0.4343</td>\n",
       "      <td>0.4648</td>\n",
       "      <td>0.4861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>PyramidalCNN</td>\n",
       "      <td>0.5322</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.5628</td>\n",
       "      <td>0.5195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LSTM</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>biLSTM</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ConvLSTM</td>\n",
       "      <td>0.4994</td>\n",
       "      <td>0.4798</td>\n",
       "      <td>0.5093</td>\n",
       "      <td>0.3885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>EEGNet</td>\n",
       "      <td>0.2652</td>\n",
       "      <td>0.0736</td>\n",
       "      <td>0.2251</td>\n",
       "      <td>0.1338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>InceptionTime</td>\n",
       "      <td>0.5466</td>\n",
       "      <td>0.5018</td>\n",
       "      <td>0.4917</td>\n",
       "      <td>0.4711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Xception</td>\n",
       "      <td>0.5209</td>\n",
       "      <td>0.5019</td>\n",
       "      <td>0.5455</td>\n",
       "      <td>0.5214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UNet</td>\n",
       "      <td>0.4299</td>\n",
       "      <td>0.7332</td>\n",
       "      <td>0.6066</td>\n",
       "      <td>0.3933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SalientSleepNet</td>\n",
       "      <td>0.8203</td>\n",
       "      <td>0.1092</td>\n",
       "      <td>0.4858</td>\n",
       "      <td>0.4326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DETRtime</td>\n",
       "      <td>0.0806</td>\n",
       "      <td>0.0199</td>\n",
       "      <td>0.1009</td>\n",
       "      <td>0.1009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AugUNet1D (ours)</td>\n",
       "      <td>0.9009</td>\n",
       "      <td>0.9007</td>\n",
       "      <td>0.8921</td>\n",
       "      <td>0.8921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Classifier  avg_f1_run1  avg_f1_run2  avg_f1_run3  avg_f1_run4\n",
       "0   Logistic Regression       0.1584       0.1584       0.1584       0.1584\n",
       "1   K-Nearest Neighbors       0.2603       0.2603       0.2603       0.2603\n",
       "2         Decision Tree       0.3289       0.3269       0.3282       0.3282\n",
       "3         Random Forest       0.2820       0.2991       0.2869       0.2869\n",
       "4                   CNN       0.4976       0.4343       0.4648       0.4861\n",
       "5          PyramidalCNN       0.5322       0.4957       0.5628       0.5195\n",
       "6                  LSTM       0.0000       0.0000       0.0000       0.0000\n",
       "7                biLSTM       0.0000       0.0000       0.0000       0.0000\n",
       "8              ConvLSTM       0.4994       0.4798       0.5093       0.3885\n",
       "9                EEGNet       0.2652       0.0736       0.2251       0.1338\n",
       "10        InceptionTime       0.5466       0.5018       0.4917       0.4711\n",
       "11             Xception       0.5209       0.5019       0.5455       0.5214\n",
       "12                 UNet       0.4299       0.7332       0.6066       0.3933\n",
       "13      SalientSleepNet       0.8203       0.1092       0.4858       0.4326\n",
       "14             DETRtime       0.0806       0.0199       0.1009       0.1009\n",
       "15     AugUNet1D (ours)       0.9009       0.9007       0.8921       0.8921"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26569f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff21fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0664dfb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92defbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370837ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e11ebd71",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b73b5f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c3323",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9af849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfce5b1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42781cc0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7cbe37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74de2423",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1eb8c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451b9c4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8da0db1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1457a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2cd34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f62bc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4e234c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e547f00b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f587bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13dc7e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4e5816d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "535a8b03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0cf1a74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae13b0c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf29eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9677166-fe55-4b39-8b6d-cdfbaec689a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OOD Kernel",
   "language": "python",
   "name": "ood_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
